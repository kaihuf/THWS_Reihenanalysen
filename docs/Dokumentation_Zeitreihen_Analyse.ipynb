{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aefd0fb7",
   "metadata": {},
   "source": [
    "#  Zeitreihenanalyse Arbeitsschritte\n",
    "\n",
    "## Einleitung\n",
    "\n",
    "Ziel dieser Analyse ist es, ein geeignetes ARIMA-Modell zu finden, das den zugrunde liegenden datengenerierenden Prozess einer Finanzzeitreihe (z.‚ÄØB. Aktienkurs) m√∂glichst realit√§tsnah abbildet. Die Analyse erfolgt nach der **Box-Jenkins-Methode**, einem etablierten Verfahren zur Modellierung, Auswahl und Prognose von Zeitreihen.\n",
    "\n",
    "### Was ist eine Zeitreihe?\n",
    "\n",
    "Eine **Zeitreihe** ist eine Folge von Beobachtungen, die in regelm√§√üigen Abst√§nden √ºber die Zeit hinweg aufgezeichnet wird ‚Äì beispielsweise t√§gliche Aktienkurse oder monatliche Arbeitslosenzahlen. Der Zweck der Zeitreihenanalyse ist es, **Strukturen wie Trends, Saisonalit√§t und Autokorrelationen zu identifizieren**, um pr√§zise Prognosen f√ºr zuk√ºnftige Werte zu erstellen.\n",
    "\n",
    "### Warum Box-Jenkins?\n",
    "\n",
    "Die **Box-Jenkins-Methode** konzentriert sich auf die Klasse der **ARIMA-Modelle (AutoRegressive Integrated Moving Average)**. Diese Modelle sind besonders flexibel und leistungsf√§hig, wenn es darum geht, komplexe Zeitreihenprozesse ohne klare saisonale Struktur zu modellieren. Die Methodik umfasst drei zentrale Schritte:\n",
    "\n",
    "1. **Identifikation** des Modells (z.‚ÄØB. Wahl der ARIMA-Ordnung),\n",
    "2. **Sch√§tzung** der Modellparameter,\n",
    "3. **Diagnosepr√ºfung** der Modellg√ºte.\n",
    "\n",
    "\n",
    "### Ziel dieser Arbeit\n",
    "\n",
    "Wir m√∂chten ein automatisiertes Analyseverfahren entwickeln, das:\n",
    "\n",
    "- eine Zeitreihe auf Stationarit√§t pr√ºft und ggf. transformiert,\n",
    "- verschiedene ARIMA-Modelle testet und bewertet,\n",
    "- auf Basis statistischer Kriterien das geeignetste Modell ausw√§hlt,\n",
    "- eine Rolling Forecast durchf√ºhrt und   \n",
    "- die Ergebnisse visuell und statistisch bewertet.\n",
    "\n",
    "Zus√§tzlich ber√ºcksichtigen wir **Modellvalidierung** (z.‚ÄØB. Residuenanalyse), **t-Tests der Parameter**, sowie die **Generierung von Prognosen**.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af1376a",
   "metadata": {},
   "source": [
    "##  Zeitreihenanalyse ‚Äì Schritt 1: Datenvorbereitung & Stationarit√§tspr√ºfung\n",
    "\n",
    "### √úberblick: Warum ist Stationarit√§t wichtig?\n",
    "\n",
    "Ein zentrales Ziel bei der Zeitreihenanalyse mit ARIMA-Modellen ist die Identifikation und Modellierung des zugrunde liegenden stochastischen Prozesses. ARIMA-Modelle (AutoRegressive Integrated Moving Average) setzen voraus, dass die analysierte Zeitreihe **station√§r** ist.\n",
    "\n",
    "**Stationarit√§t** bedeutet, dass die statistischen Eigenschaften der Zeitreihe ‚Äì insbesondere der Erwartungswert, die Varianz und die Autokorrelation ‚Äì √ºber die Zeit hinweg konstant bleiben. Wenn dies nicht gegeben ist (z.‚ÄØB. bei Trends, saisonalen Effekten oder Heteroskedastizit√§t), kann das Modell fehlspezifiziert werden.\n",
    "\n",
    "---\n",
    "\n",
    "###  Datenimport & Visualisierung der Originalreihe\n",
    "\n",
    "Wir importieren zun√§chst die Aktienkurs-Zeitreihe von Samsung (‚ÄûAdjusted Close‚Äú-Preise), konvertieren das Datum in ein geeignetes Format und erstellen eine erste Visualisierung der urspr√ºnglichen, **nicht transformierten** Zeitreihe.\n",
    "\n",
    "\n",
    "**Beobachtung:**  \n",
    "Die urspr√ºngliche Zeitreihe zeigt visuell einen starken Trend ‚Äì sowohl auf- als auch abw√§rtsgerichtet in unterschiedlichen Phasen. Solche Trends deuten auf **Nichtstationarit√§t** hin.\n",
    "\n",
    "---\n",
    "\n",
    "###  Stationarit√§tstests: ADF und KPSS\n",
    "\n",
    "Um Stationarit√§t statistisch zu pr√ºfen, wenden wir zwei komplement√§re Tests an:\n",
    "\n",
    "#### üîπ Augmented Dickey-Fuller-Test (ADF)\n",
    "- **Nullhypothese (H‚ÇÄ):** Die Zeitreihe hat eine Einheitwurzel ‚Üí *nicht station√§r*\n",
    "- **Alternativhypothese (H‚ÇÅ):** Stationarit√§t liegt vor\n",
    "- Wir lehnen H‚ÇÄ ab, wenn der **p-Wert < 0.05**\n",
    "\n",
    "**Testformel:**\n",
    "\n",
    "$$\n",
    "\\Delta y_t = \\alpha + \\beta t + \\gamma y_{t-1} + \\sum_{i=1}^{p} \\delta_i \\Delta y_{t-i} + \\varepsilon_t\n",
    "$$\n",
    "\n",
    "\n",
    "#### üîπ KPSS-Test (Kwiatkowski-Phillips-Schmidt-Shin)\n",
    "- **Nullhypothese (H‚ÇÄ):** Die Zeitreihe ist station√§r (gegen Trendstationarit√§t)\n",
    "- **Alternativhypothese (H‚ÇÅ):** Die Zeitreihe ist nicht station√§r\n",
    "- Wir behalten H‚ÇÄ bei, wenn **p-Wert > 0.05**\n",
    "\n",
    "#### üîπ Phillips-Perron-Test (PP)\n",
    "\n",
    "Der Phillips-Perron-Test ist eine weitere Methode zur Pr√ºfung auf Einheitwurzeln und √§hnelt dem ADF, ber√ºcksichtigt aber heteroskedastische und serielle Korrelation in den Residuen auf flexible Weise.\n",
    "\n",
    "- **Nullhypothese (H‚ÇÄ):** Die Zeitreihe besitzt eine Einheitwurzel ‚Üí *nicht station√§r*  \n",
    "- **Alternativhypothese (H‚ÇÅ):** Stationarit√§t liegt vor  \n",
    "- Wir lehnen H‚ÇÄ ab, wenn der **p-Wert < 0.05**\n",
    "\n",
    "**Testidee:**  \n",
    "PP erweitert das klassische Dickey‚ÄìFuller-Modell  \n",
    "$\n",
    "\\Delta y_t = \\alpha + \\beta t + \\gamma\\,y_{t-1} + \\varepsilon_t\n",
    "$\n",
    "um eine semi-nonparametrische Korrektur der Teststatistik, um m√∂gliche Autokorrelation und Heteroskedastizit√§t in den Fehlern $ \\varepsilon_t $ zu entfernen, ohne explizit verz√∂gerte Differenzen einzuf√ºgen.\n",
    "\n",
    "**Teststatistik:**  \n",
    "$$\n",
    "Z_{\\rho} = T\\big(\\hat{\\rho}-1\\big) - \\tfrac{1}{2} \\;\\frac{\\hat{\\sigma}^2_{\\Delta\\varepsilon}}{\\hat{\\sigma}^2_{\\varepsilon}}\n",
    "$$  \n",
    "wobei  \n",
    "\n",
    "$\\hat{\\rho}$ der gesch√§tzte AR-Parameter ist,  \n",
    "- $\\hat{\\sigma}^2_{\\varepsilon}$ die Varianz der Roh-Residuen und  \n",
    "- $\\hat{\\sigma}^2_{\\Delta\\varepsilon}$ die Varianz der Residuen-Differenzen (korrigiert um serielle Korrelation)\n",
    "\n",
    "**Vorteil gegen√ºber ADF:**  \n",
    "Keine manuelle Wahl der Verz√∂gerungen \\(p\\) n√∂tig ‚Äì die Korrektur erfolgt implizit √ºber eine Newey-West-artige Sch√§tzung.\n",
    "\n",
    "**Praxis-Tipp:**  \n",
    "Vergleiche PP- und ADF-Ergebnisse: Wenn beide zu √§hnlichen Entscheidungen kommen, erh√∂hst Du das Vertrauen in das Testergebnis.\n",
    "\n",
    "**Kombination beider Tests:**  \n",
    "Sie erm√∂glicht eine robustere Beurteilung, da sie aus zwei Perspektiven pr√ºfen.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "###  Transformationen zur Erreichung von Stationarit√§t\n",
    "\n",
    "Um die urspr√ºngliche Reihe in eine station√§re zu √ºberf√ºhren, wenden wir mehrere Transformationen an ‚Äì jede mit einem spezifischen Ziel:\n",
    "\n",
    "| Transformation                        | Zweck |\n",
    "|--------------------------------------|-------|\n",
    "| **1. Differenzierung**:  $$ y_t - y_{t-1} $$  | Entfernt lineare Trends |\n",
    "| **2. Differenzierung**: $$ (y_t - y_{t-1}) - (y_{t-1} - y_{t-2}) $$ | Entfernt quadratische/komplexere Trends |\n",
    "| **Logarithmierung**: $$ \\log(y_t) $$ | Stabilisiert Varianz (z.‚ÄØB. bei exponentiellem Wachstum) |\n",
    "| **Log-Differenz**: $$ \\log(y_t) - \\log(y_{t-1}) $$ | Kombiniert Trendentfernung und Varianzstabilisierung |\n",
    "| **Moving Average Residuum**: $$ y_t - \\overline{y}_{t,window} $$ | Entfernt gleitenden Mittelwert (Trend) |\n",
    "| **Exponentielle Gl√§ttung** | Entfernt Trend mit h√∂herem Gewicht auf j√ºngere Werte |\n",
    "| **HP-Filter (Hodrick-Prescott)** | Trennt Trend- und Zykluskomponente der Reihe |\n",
    "\n",
    "Nach jeder Transformation f√ºhren wir erneut ADF- und KPSS-Tests durch, um den Erfolg zu bewerten.\n",
    "\n",
    "---\n",
    "\n",
    "###  Visualisierung der Transformationen\n",
    "\n",
    "Die transformierten Zeitreihen werden grafisch dargestellt ‚Äì inklusive der jeweiligen Testergebnisse (ADF & KPSS) in Textboxen.\n",
    "\n",
    "**Beispiel:**\n",
    "\n",
    "```text\n",
    "ADF p = 0.021 ‚Üí Station√§r  \n",
    "KPSS p = 0.08 ‚Üí Station√§r\n",
    "```\n",
    "\n",
    "Dies erlaubt eine schnelle visuelle und numerische Bewertung jeder Transformation.\n",
    "\n",
    "---\n",
    "\n",
    "###  Auswahl der besten Transformation\n",
    "\n",
    "Zur systematischen Auswahl verwenden wir eine **Scoring-Funktion**, die beide Tests kombiniert:\n",
    "\n",
    "$\n",
    "\\text{Stationarit√§tsscore} = p_{\\text{ADF}} + (1 - p_{\\text{KPSS}})\n",
    "$\n",
    "\n",
    "- Ziel: **Minimaler Score**\n",
    "- Begr√ºndung: Kleine ADF-p-Werte + gro√üe KPSS-p-Werte ‚Üí station√§r\n",
    "\n",
    "Der Name und die Serie der ‚Äûbesten Transformation‚Äú werden gespeichert.\n",
    "\n",
    "---\n",
    "\n",
    "###  Rolling-Statistiken und ACF: Visuelle Stationarit√§tspr√ºfung\n",
    "\n",
    "Wir berechnen und visualisieren:\n",
    "\n",
    "- **Rolling Mean** (Gleitender Durchschnitt, Fenster = 20 Tage)\n",
    "- **Rolling Standard Deviation**\n",
    "- **ACF-Werte bei Lag 1 & 2**\n",
    "\n",
    "Ziel: Station√§re Reihen haben **konstante Mittelwerte und Varianzen**, und die ACF f√§llt schnell ab.\n",
    "\n",
    "F√ºr jede Transformation:\n",
    "\n",
    "```python\n",
    "rolling_mean = series.rolling(window=20).mean()\n",
    "rolling_std = series.rolling(window=20).std()\n",
    "acf_vals = acf(series, nlags=2)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  ACF- und PACF-Plots\n",
    "\n",
    "F√ºr zwei zentrale Reihen (beste Transformation + Log-Differenz) erstellen wir **ACF- und PACF-Plots mit Konfidenzintervallen**.\n",
    "\n",
    "#### ACF (Autokorrelationsfunktion):\n",
    "Zeigt Korrelation von $ y_t $ mit $ y_{t-k} $. Wichtig f√ºr MA-Komponente im ARIMA(p, d, q).\n",
    "\n",
    "#### PACF (Partielle Autokorrelationsfunktion):\n",
    "Zeigt \"direkten\" Effekt des Lags $ k $ auf $ y_t $, ohne Zwischenschritte. Wichtig f√ºr AR-Komponente.\n",
    "\n",
    "Signifikante Lags au√üerhalb der Konfidenzgrenzen $ ¬±1.96/‚àön $ deuten auf relevante Modellbestandteile hin.\n",
    "\n",
    "---\n",
    "\n",
    "##  Fazit Schritt 1\n",
    "\n",
    "- Die Zeitreihe wurde erfolgreich transformiert, um Stationarit√§t zu erreichen.\n",
    "- Durch Kombination von ADF- und KPSS-Tests konnte eine robuste Bewertung vorgenommen werden.\n",
    "- Die **log-differenzierte Zeitreihe** erwies sich als beste Transformation.\n",
    "- ACF- und PACF-Plots legen die Grundlage f√ºr die sp√§tere Modellauswahl (ARIMA-Identifikation).\n",
    "\n",
    "Wir sind nun bereit f√ºr **Modellidentifikation und Parametersch√§tzung**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140b2edd",
   "metadata": {},
   "source": [
    "##  Schritt 2: ARIMA-Modellidentifikation via AIC/BIC\n",
    "\n",
    "Nachdem wir im ersten Schritt die Zeitreihe erfolgreich in eine **station√§re Form** gebracht haben (z.‚ÄØB. durch Log-Differenzierung), k√∂nnen wir nun ein geeignetes ARIMA-Modell identifizieren.\n",
    "\n",
    "---\n",
    "\n",
    "###  Hintergrund: ARIMA(p, d, q)\n",
    "\n",
    "Ein ARIMA-Modell kombiniert drei Komponenten:\n",
    "\n",
    "- **AR (p)**: AutoRegressive-Teil ‚Üí beschreibt, wie der aktuelle Wert von den vorherigen Werten abh√§ngt  \n",
    "- **I (d)**: Integrated-Teil ‚Üí beschreibt, wie viele Differenzierungen notwendig sind, um Stationarit√§t zu erreichen  \n",
    "- **MA (q)**: Moving Average-Teil ‚Üí beschreibt den Einfluss vergangener Sch√§tzfehler (Residuen)\n",
    "\n",
    "Die allgemeine Form eines ARIMA(p,d,q)-Modells ist:\n",
    "\n",
    "$$\n",
    "\\Delta y_t = \\alpha + \\beta t + \\gamma y_{t-1} + \\sum_{i=1}^{p} \\delta_i \\Delta y_{t-i} + \\varepsilon_t\n",
    "$$\n",
    "\n",
    "\n",
    "Dabei ist:\n",
    "- $ y_t $: aktueller Wert der Zeitreihe  \n",
    "- $ \\phi_i $: AR-Koeffizienten  \n",
    "- $ \\theta_i $: MA-Koeffizienten  \n",
    "- $ \\varepsilon_t $: wei√üe Rauschkomponente (Zufallsfehler)\n",
    "\n",
    "---\n",
    "\n",
    "###  Ziel: Auswahl des besten (p,d,q)-Modells\n",
    "\n",
    "Um das geeignetste Modell zu finden, wurden alle sinnvollen Kombinationen von p, d und q getestet. Die Auswahl basiert auf:\n",
    "\n",
    "#### Bewertungskriterien:\n",
    "\n",
    "| Kriterium | Ziel      | Formel (vereinfacht)                      | Bestrafung f√ºr Komplexit√§t? |\n",
    "|-----------|-----------|-------------------------------------------|------------------------------|\n",
    "| **AIC**   | Modellg√ºte | $$ \\text{AIC} = -2 \\log(L) + 2k \\ $$         | Ja (milder)                  |\n",
    "| **BIC**   | Modellg√ºte | $$ \\text{BIC} = -2 \\log(L) + k \\log(n) \\ $$ | Ja (st√§rker)                 |\n",
    "\n",
    "- $ \\log(L) $: Log-Likelihood des Modells  \n",
    "- $ k $: Anzahl der gesch√§tzten Parameter  \n",
    "- $ n $: Anzahl der Beobachtungen\n",
    "\n",
    "Ziel ist es, ein Modell mit m√∂glichst **niedrigem AIC/BIC** zu finden. Dabei gilt:\n",
    "\n",
    "- **AIC** bevorzugt Modelle mit besserer Vorhersagekraft (weniger Bestrafung f√ºr Komplexit√§t)\n",
    "- **BIC** bevorzugt sparsamere Modelle (mehr Bestrafung f√ºr viele Parameter)\n",
    "\n",
    "---\n",
    "\n",
    "###  Beispielausgabe: Top 10 Modelle\n",
    "\n",
    "| p | d | q | AIC     | BIC     |\n",
    "|---|---|---|---------|---------|\n",
    "| 2 | 0 | 2 | 1234.56 | 1250.78 |\n",
    "| 1 | 0 | 1 | 1240.91 | 1251.33 |\n",
    "| 3 | 0 | 0 | 1243.12 | 1257.01 |\n",
    "| 2 | 0 | 1 | 1244.88 | 1258.90 |\n",
    "| 1 | 0 | 2 | 1246.78 | 1260.22 |\n",
    "\n",
    "Aus dieser Tabelle erkennt man, dass das Modell mit **(p=2, d=0, q=2)** den niedrigsten AIC aufweist und damit aktuell das beste Kandidatenmodell ist.\n",
    "\n",
    "---\n",
    "\n",
    "###  Fazit Schritt 2\n",
    "\n",
    "- Durch eine systematische Suche √ºber alle Modellkombinationen wurde das ARIMA-Modell mit der besten Balance aus **G√ºte** und **Komplexit√§t** identifiziert.\n",
    "- Das Kriterium der Wahl war der **Akaike Information Criterion (AIC)**, optional erg√§nzt durch **BIC** zur √úberpr√ºfung.\n",
    "- Dieses Modell kann nun im n√§chsten Schritt gesch√§tzt und validiert werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd62a793",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be8ea32d",
   "metadata": {},
   "source": [
    "##  Schritt 3: Visuelle Forecast-Analyse mit gestuften Trainingsdaten\n",
    "\n",
    "Nachdem wir mit Hilfe von AIC/BIC ein vielversprechendes ARIMA(p,d,q)-Modell ausgew√§hlt haben (z.‚ÄØB. ARIMA(2,0,0)), wollen wir dieses Modell nun **visuell testen**, und zwar in verschiedenen Phasen der Zeitreihe.\n",
    "\n",
    "---\n",
    "\n",
    "###  Ziel: Forecast-G√ºte √ºber mehrere Zeitabschnitte hinweg beurteilen\n",
    "\n",
    "Statt das Modell nur einmal auf die gesamte Serie zu trainieren, wird die Zeitreihe stufenweise aufgeteilt:\n",
    "\n",
    "| Trainingsanteil | Forecastzeitraum | Ziel |\n",
    "|------------------|------------------|------|\n",
    "| 40‚ÄØ%             | n√§chste 15‚ÄØ%     | Fr√ºhprognose auf kurzer Datenbasis  \n",
    "| 55‚ÄØ%             | n√§chste 15‚ÄØ%     | Stabileres Modell  \n",
    "| 70‚ÄØ%             | n√§chste 15‚ÄØ%     | Fast vollst√§ndiges Modell  \n",
    "| 85‚ÄØ%            | n√§chste 15% | Fast vollst√§ndiges Modell \n",
    "| 100‚ÄØ%            | +15‚ÄØ% extrapoliert| Finaler Forecast √ºber den Rand hinaus  \n",
    "\n",
    "So k√∂nnen wir grafisch nachvollziehen, **wie stabil und robust** das Modell √ºber verschiedene Zeitabschnitte funktioniert.\n",
    "\n",
    "---\n",
    "\n",
    "###  Methodik\n",
    "\n",
    "1. **Split der Zeitreihe**  \n",
    "   Die Serie wird schrittweise in 5 Etappen unterteilt (40‚ÄØ%, 55‚ÄØ%, 70‚ÄØ%, 85‚ÄØ%, 100 %).\n",
    "\n",
    "2. **Modellanpassung je Etappe**  \n",
    "   F√ºr jede Teilserie wird das **ARIMA(p,d,q)-Modell** neu gesch√§tzt.\n",
    "\n",
    "3. **Prognoseberechnung**  \n",
    "   F√ºr jede Etappe wird ein Forecast √ºber eine feste L√§nge (z.‚ÄØB. 15‚ÄØ% der Gesamtl√§nge) berechnet.\n",
    "\n",
    "4. **Visualisierung**  \n",
    "  \n",
    "\n",
    "---\n",
    "\n",
    "###  Beispielhafte Plotbeschreibung\n",
    "\n",
    "Wenn z.‚ÄØB. die Zeitreihe 1000 Werte hat, ergibt sich bei 80‚ÄØ% Training und 20‚ÄØ% Forecast:\n",
    "\n",
    "- **Trainingsbereich**: Werte 0 bis 799  \n",
    "- **Forecast**: Werte 800 bis 999  \n",
    "- **Ziel**: Pr√ºfen, ob der Forecast strukturell dem tats√§chlichen Verlauf folgt\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "###  Fazit Schritt 3\n",
    "\n",
    "- Durch die gestufte Visualisierung bekommt man ein Gef√ºhl daf√ºr, **wann das ARIMA-Modell stabil prognostiziert** und wo es evtl. versagt.\n",
    "- Diese Methode ist **besonders hilfreich**, um **Overfitting bei kurzer Trainingsphase** zu erkennen.\n",
    "- In Kombination mit der vorherigen AIC/BIC-Auswahl ist das ein robuster Weg, um die Prognosequalit√§t eines Zeitreihenmodells visuell zu pr√ºfen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d66ef",
   "metadata": {},
   "source": [
    "##  Schritt 4: Rolling Forecasts auf Originalskala (zur√ºcktransformiert)\n",
    "\n",
    "Nachdem wir ein geeignetes ARIMA-Modell trainiert und erste Forecasts durchgef√ºhrt haben, folgt nun der **entscheidende Praxisschritt**:  \n",
    "Wir zeigen **rollierende Forecasts** ‚Äì aber diesmal **auf der realen Preisskala**, nicht auf den log-differenzierten Werten.\n",
    "\n",
    "---\n",
    "\n",
    "###  Ziel: Modellg√ºte auf der urspr√ºnglichen Skala beurteilen\n",
    "\n",
    "Das Modell wurde auf **log-transformierten und differenzierten Daten** trainiert, da diese Transformation station√§r macht.  \n",
    "Jetzt kehren wir die Transformation wieder um:\n",
    "\n",
    "1. **Kumulative Summe** der differenzierten Forecasts  \n",
    "2. **Addition des letzten Log-Wertes** vor dem Forecast  \n",
    "3. **Exponentialfunktion**, um von $ log(X) $ zur√ºck zu $ X $ zu kommen\n",
    "\n",
    "> Ergebnis: Ein Forecast der tats√§chlichen Preisentwicklung \n",
    "\n",
    "---\n",
    "\n",
    "###  Methodik\n",
    "\n",
    "#### Rolling Forecast-Stufen:\n",
    "\n",
    "| Trainingsanteil | Forecastzeitraum  | Zielsetzung |\n",
    "|-----------------|-------------------|-------------|\n",
    "| 40‚ÄØ%            | n√§chste 15‚ÄØ%      | Erste Prognose auf kleiner Datenbasis  \n",
    "| 55‚ÄØ%            | n√§chste 15‚ÄØ%      | Etwas robuster  \n",
    "| 70‚ÄØ%            | n√§chste 15‚ÄØ%      | Fast vollst√§ndige Datenlage  \n",
    "| 85‚ÄØ%            | n√§chste 15 %      | Fast vollst√§ndige Datenlage \n",
    "| 100‚ÄØ%           | +15‚ÄØ% extrapoliert| Finaler Forecast √ºber den Rand hinaus   \n",
    "\n",
    "#### Vorgehen pro Stufe:\n",
    "\n",
    "- **Modelltraining** auf einem festen Anteil der geloggten Serie\n",
    "- **Forecast** √ºber die n√§chsten 15‚ÄØ% (ab Trainingsende)\n",
    "- **Zur√ºcktransformation**:\n",
    "  - Letzter Log-Wert + kumulierte Differenzen\n",
    "  - Dann: `exp()` anwenden ‚Üí Originalwerte\n",
    "- **Plot-Vergleich**:\n",
    "  - Hellgrau = vollst√§ndige Originalserie\n",
    "  - Rot = Forecast (auf Originalskala)\n",
    "  - Blau (gestrichelt) = Tats√§chliche Entwicklung (sofern bekannt)\n",
    "\n",
    "---\n",
    "\n",
    "###  Visualisierungsziel\n",
    "\n",
    "Ein Plot pro Stufe zeigt:\n",
    "\n",
    "- Wie **gut das Modell zuk√ºnftige Entwicklungen approximiert**\n",
    "- Ob es **Trendwenden erkennt**\n",
    "- Ob es **√ºbersch√§tzt oder untersch√§tzt**\n",
    "- Wo es z.‚ÄØB. **zu langsam reagiert**\n",
    "\n",
    "Die letzte Grafik (100‚ÄØ%) zeigt die echte **Zukunftsprognose** ‚Äì also was wir erwarten w√ºrden, wenn der bisherige Verlauf anhielte.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be45b73",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4774565a",
   "metadata": {},
   "source": [
    "## Schritt 5: Residuenanalyse & Modell-Diagnose (ARIMA)\n",
    "\n",
    "Ein statistisches Modell wie ARIMA ist nur dann sinnvoll, wenn seine **Fehler (Residuen)** bestimmten Annahmen gen√ºgen.  \n",
    "Die Analyse der Residuen zeigt uns, ob unser Modell sauber gearbeitet hat ‚Äì oder ob es noch systematische Muster oder Schw√§chen gibt.\n",
    "\n",
    "---\n",
    "\n",
    "### Ziel der Residuenanalyse:\n",
    "\n",
    "Ein gutes Modell hinterl√§sst **\"wei√ües Rauschen\"** ‚Äì das hei√üt:\n",
    "\n",
    "- Fehler sind zuf√§llig verteilt\n",
    "- Es gibt **keine Autokorrelation**\n",
    "- Die Fehler sind **normalverteilt**\n",
    "- Die Varianz ist konstant\n",
    "- Der Mittelwert der Fehler ist nahe **null**\n",
    "\n",
    "---\n",
    "\n",
    "### Wichtige Tests zur Residuenanalyse\n",
    "\n",
    "#### 1. Ljung-Box Test\n",
    "\n",
    "Der Ljung-Box-Test pr√ºft, ob es **Autokorrelation** in den Residuen gibt ‚Äì also ob heutige Fehler mit vergangenen Fehlern zusammenh√§ngen.\n",
    "\n",
    "- **Nullhypothese**: Es gibt **keine Autokorrelation** ‚Üí gut!\n",
    "- **Interpretation**:  \n",
    "  - Wenn **p-Wert > 0.05** ‚Üí Fehler sind unkorreliert (‚úì)\n",
    "  - Wenn **p-Wert ‚â§ 0.05** ‚Üí Es gibt Korrelation (‚úó), Modell evtl. unzureichend\n",
    "\n",
    "#### 2. Jarque-Bera Test\n",
    "\n",
    "Der Jarque-Bera-Test pr√ºft, ob die Residuen **normalverteilt** sind.\n",
    "\n",
    "- **Nullhypothese**: Die Residuen sind **normalverteilt**\n",
    "- **Interpretation**:  \n",
    "  - Wenn **p-Wert > 0.05** ‚Üí Normalverteilung gegeben (‚úì)\n",
    "  - Wenn **p-Wert ‚â§ 0.05** ‚Üí Abweichung von Normalverteilung (‚úó), Modellfehler oder Transformation n√∂tig\n",
    "\n",
    "---\n",
    "\n",
    "### Weitere Plots zur Diagnose\n",
    "\n",
    "| Plot                         | Beschreibung                                 | Ziel                                         |\n",
    "|------------------------------|----------------------------------------------|----------------------------------------------|\n",
    "| **Residuen-Zeitreihe**       | Fehler √ºber die Zeit                         | Keine offensichtlichen Muster, keine Trends |\n",
    "| **Histogramm + Normalverteilung** | Vergleich Fehlerverteilung vs. Normalverteilung | M√∂glichst symmetrisch und glockenf√∂rmig     |\n",
    "| **Q-Q-Plot (Quantil-Quantil)** | Pr√ºft Normalverteilung grafisch              | Punkte sollten auf Diagonale liegen         |\n",
    "\n",
    "---\n",
    "\n",
    "### Statistische Modell-Zusammenfassung (`model_fit.summary()`)\n",
    "\n",
    "- Zeigt **Koeffizienten** mit **t-Statistiken**\n",
    "- Wenn `|t| > 2`, dann sind die Parameter h√§ufig **statistisch signifikant**\n",
    "- AIC und BIC helfen bei Modellvergleich\n",
    "\n",
    "---\n",
    "\n",
    "## RESIDUENANALYSE - ZUSAMMENFASSUNG\n",
    "\n",
    "**SAMSUNG:**  \n",
    "- Ljung-Box Test (p-Wert): 0.9722  \n",
    "  ‚Üí ‚úì Keine Autokorrelation  \n",
    "- Jarque-Bera Test (p-Wert): 0.0000  \n",
    "  ‚Üí ‚úó Keine Normalverteilung  \n",
    "- Residuen Mittelwert: 0.000002  \n",
    "- Residuen Std: 0.0215  \n",
    "\n",
    "**DAIMLER:**  \n",
    "- Ljung-Box Test (p-Wert): 0.0470  \n",
    "  ‚Üí ‚úó Autokorrelation vorhanden  \n",
    "- Jarque-Bera Test (p-Wert): 0.0000  \n",
    "  ‚Üí ‚úó Keine Normalverteilung  \n",
    "- Residuen Mittelwert: 0.000214  \n",
    "- Residuen Std: 0.0213  \n",
    "\n",
    "**MICROSOFT:**  \n",
    "- Ljung-Box Test (p-Wert): 0.0000  \n",
    "  ‚Üí ‚úó Autokorrelation vorhanden  \n",
    "- Jarque-Bera Test (p-Wert): 0.0000  \n",
    "  ‚Üí ‚úó Keine Normalverteilung  \n",
    "- Residuen Mittelwert: 0.000447  \n",
    "- Residuen Std: 0.0212  \n",
    "\n",
    "---\n",
    "\n",
    "## INTERPRETATION\n",
    "\n",
    "- **Samsung:**  \n",
    "  Residuen scheinen unkorreliert, aber nicht normalverteilt. Das Modell beschreibt die Dynamik gut, k√∂nnte aber bei Verteilung der Fehler verbessert werden (z.‚ÄØB. durch Transformationen oder robustere Verfahren).\n",
    "\n",
    "- **Daimler & Microsoft:**  \n",
    "  Beide Modelle zeigen **Autokorrelation** und **keine Normalverteilung** der Residuen. Das deutet darauf hin, dass hier noch **systematische Muster** in den Daten nicht erfasst wurden.  \n",
    "  ‚Üí Empfehlung: Modellierung (p,d,q) √ºberdenken oder alternative Modelle wie SARIMA oder GARCH in Betracht ziehen.\n",
    "\n",
    "---\n",
    "\n",
    "## Fazit Schritt 5\n",
    "\n",
    "- Die **Residuenanalyse zeigt**, ob die statistischen Annahmen des ARIMA-Modells erf√ºllt sind.\n",
    "- Nur wenn die Fehler zuf√§llig, unkorreliert und normalverteilt sind, ist die Prognose statistisch **zuverl√§ssig**.\n",
    "- Abweichungen (wie bei Daimler/Microsoft) zeigen: Modell ggf. **nicht ausreichend angepasst**.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d9f540",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
