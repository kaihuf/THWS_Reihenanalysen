{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aefd0fb7",
   "metadata": {},
   "source": [
    "#  Zeitreihenanalyse mit der Box-Jenkins-Methode\n",
    "\n",
    "## Einleitung\n",
    "\n",
    "Ziel dieser Analyse ist es, ein geeignetes ARIMA-Modell zu finden, das den zugrunde liegenden datengenerierenden Prozess einer Finanzzeitreihe (z.‚ÄØB. Aktienkurs) m√∂glichst realit√§tsnah abbildet. Die Analyse erfolgt nach der **Box-Jenkins-Methode**, einem etablierten Verfahren zur Modellierung, Auswahl und Prognose von Zeitreihen.\n",
    "\n",
    "### Was ist eine Zeitreihe?\n",
    "\n",
    "Eine **Zeitreihe** ist eine Folge von Beobachtungen, die in regelm√§√üigen Abst√§nden √ºber die Zeit hinweg aufgezeichnet wird ‚Äì beispielsweise t√§gliche Aktienkurse oder monatliche Arbeitslosenzahlen. Der Zweck der Zeitreihenanalyse ist es, **Strukturen wie Trends, Saisonalit√§t und Autokorrelationen zu identifizieren**, um pr√§zise Prognosen f√ºr zuk√ºnftige Werte zu erstellen.\n",
    "\n",
    "### Warum Box-Jenkins?\n",
    "\n",
    "Die **Box-Jenkins-Methode** konzentriert sich auf die Klasse der **ARIMA-Modelle (AutoRegressive Integrated Moving Average)**. Diese Modelle sind besonders flexibel und leistungsf√§hig, wenn es darum geht, komplexe Zeitreihenprozesse ohne klare saisonale Struktur zu modellieren. Die Methodik umfasst drei zentrale Schritte:\n",
    "\n",
    "1. **Identifikation** des Modells (z.‚ÄØB. Wahl der ARIMA-Ordnung),\n",
    "2. **Sch√§tzung** der Modellparameter,\n",
    "3. **Diagnosepr√ºfung** der Modellg√ºte.\n",
    "\n",
    "Diese Schritte basieren auf verschiedenen statistischen Tests, Visualisierungen und Modellvergleichsmetriken wie dem **Akaike Information Criterion (AIC)** oder dem **Bayesian Information Criterion (BIC)**.\n",
    "\n",
    "### Ziel dieser Arbeit\n",
    "\n",
    "Wir m√∂chten ein automatisiertes Analyseverfahren entwickeln, das:\n",
    "\n",
    "- eine Zeitreihe auf Stationarit√§t pr√ºft und ggf. transformiert,\n",
    "- verschiedene ARIMA-Modelle testet und bewertet,\n",
    "- auf Basis statistischer Kriterien das geeignetste Modell ausw√§hlt,\n",
    "- eine **Out-of-Sample-Prognose** durchf√ºhrt und\n",
    "- die Ergebnisse visuell und statistisch bewertet.\n",
    "\n",
    "Zus√§tzlich ber√ºcksichtigen wir **Modellvalidierung** (z.‚ÄØB. Residuenanalyse), **t-Tests der Parameter**, sowie die **Generierung von Prognosen** inklusive **Konfidenzintervallen**.\n",
    "\n",
    "---\n",
    "\n",
    "Im Folgenden werden die Schritte im Detail mit zugeh√∂rigem Code und statistischem Hintergrund dokumentiert.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af1376a",
   "metadata": {},
   "source": [
    "##  Zeitreihenanalyse ‚Äì Schritt 1: Datenvorbereitung & Stationarit√§tspr√ºfung\n",
    "\n",
    "### √úberblick: Warum ist Stationarit√§t wichtig?\n",
    "\n",
    "Ein zentrales Ziel bei der Zeitreihenanalyse mit ARIMA-Modellen ist die Identifikation und Modellierung des zugrunde liegenden stochastischen Prozesses. ARIMA-Modelle (AutoRegressive Integrated Moving Average) setzen voraus, dass die analysierte Zeitreihe **station√§r** ist.\n",
    "\n",
    "**Stationarit√§t** bedeutet, dass die statistischen Eigenschaften der Zeitreihe ‚Äì insbesondere der Erwartungswert, die Varianz und die Autokorrelation ‚Äì √ºber die Zeit hinweg konstant bleiben. Wenn dies nicht gegeben ist (z.‚ÄØB. bei Trends, saisonalen Effekten oder Heteroskedastizit√§t), kann das Modell fehlspezifiziert werden.\n",
    "\n",
    "---\n",
    "\n",
    "###  Datenimport & Visualisierung der Originalreihe\n",
    "\n",
    "Wir importieren zun√§chst die Aktienkurs-Zeitreihe von Samsung (‚ÄûAdjusted Close‚Äú-Preise), konvertieren das Datum in ein geeignetes Format und erstellen eine erste Visualisierung der urspr√ºnglichen, **nicht transformierten** Zeitreihe.\n",
    "\n",
    "\n",
    "**Beobachtung:**  \n",
    "Die urspr√ºngliche Zeitreihe zeigt visuell einen starken Trend ‚Äì sowohl auf- als auch abw√§rtsgerichtet in unterschiedlichen Phasen. Solche Trends deuten auf **Nichtstationarit√§t** hin.\n",
    "\n",
    "---\n",
    "\n",
    "###  Stationarit√§tstests: ADF und KPSS\n",
    "\n",
    "Um Stationarit√§t statistisch zu pr√ºfen, wenden wir zwei komplement√§re Tests an:\n",
    "\n",
    "#### üîπ Augmented Dickey-Fuller-Test (ADF)\n",
    "- **Nullhypothese (H‚ÇÄ):** Die Zeitreihe hat eine Einheitwurzel ‚Üí *nicht station√§r*\n",
    "- **Alternativhypothese (H‚ÇÅ):** Stationarit√§t liegt vor\n",
    "- Wir lehnen H‚ÇÄ ab, wenn der **p-Wert < 0.05**\n",
    "\n",
    "**Testformel:**\n",
    "\n",
    "\\[\n",
    "\\Delta y_t = \\alpha + \\beta t + \\gamma y_{t-1} + \\sum_{i=1}^{p} \\delta_i \\Delta y_{t-i} + \\varepsilon_t\n",
    "\\]\n",
    "\n",
    "#### üîπ KPSS-Test (Kwiatkowski-Phillips-Schmidt-Shin)\n",
    "- **Nullhypothese (H‚ÇÄ):** Die Zeitreihe ist station√§r (gegen Trendstationarit√§t)\n",
    "- **Alternativhypothese (H‚ÇÅ):** Die Zeitreihe ist nicht station√§r\n",
    "- Wir behalten H‚ÇÄ bei, wenn **p-Wert > 0.05**\n",
    "\n",
    "**Kombination beider Tests:**  \n",
    "Sie erm√∂glicht eine robustere Beurteilung, da sie aus zwei Perspektiven pr√ºfen.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "###  Transformationen zur Erreichung von Stationarit√§t\n",
    "\n",
    "Um die urspr√ºngliche Reihe in eine station√§re zu √ºberf√ºhren, wenden wir mehrere Transformationen an ‚Äì jede mit einem spezifischen Ziel:\n",
    "\n",
    "| Transformation                        | Zweck |\n",
    "|--------------------------------------|-------|\n",
    "| **1. Differenzierung**: \\( y_t - y_{t-1} \\) | Entfernt lineare Trends |\n",
    "| **2. Differenzierung**: \\( (y_t - y_{t-1}) - (y_{t-1} - y_{t-2}) \\) | Entfernt quadratische/komplexere Trends |\n",
    "| **Logarithmierung**: \\( \\log(y_t) \\) | Stabilisiert Varianz (z.‚ÄØB. bei exponentiellem Wachstum) |\n",
    "| **Log-Differenz**: \\( \\log(y_t) - \\log(y_{t-1}) \\) | Kombiniert Trendentfernung und Varianzstabilisierung |\n",
    "| **Moving Average Residuum**: \\( y_t - \\overline{y}_{t,window} \\) | Entfernt gleitenden Mittelwert (Trend) |\n",
    "| **Exponentielle Gl√§ttung** | Entfernt Trend mit h√∂herem Gewicht auf j√ºngere Werte |\n",
    "| **HP-Filter (Hodrick-Prescott)** | Trennt Trend- und Zykluskomponente der Reihe |\n",
    "\n",
    "Nach jeder Transformation f√ºhren wir erneut ADF- und KPSS-Tests durch, um den Erfolg zu bewerten.\n",
    "\n",
    "---\n",
    "\n",
    "###  Visualisierung der Transformationen\n",
    "\n",
    "Die transformierten Zeitreihen werden grafisch dargestellt ‚Äì inklusive der jeweiligen Testergebnisse (ADF & KPSS) in Textboxen.\n",
    "\n",
    "**Beispiel:**\n",
    "\n",
    "```text\n",
    "ADF p = 0.021 ‚Üí Station√§r  \n",
    "KPSS p = 0.08 ‚Üí Station√§r\n",
    "```\n",
    "\n",
    "Dies erlaubt eine schnelle visuelle und numerische Bewertung jeder Transformation.\n",
    "\n",
    "---\n",
    "\n",
    "###  Auswahl der besten Transformation\n",
    "\n",
    "Zur systematischen Auswahl verwenden wir eine **Scoring-Funktion**, die beide Tests kombiniert:\n",
    "\n",
    "\\[\n",
    "\\text{Stationarit√§tsscore} = p_{\\text{ADF}} + (1 - p_{\\text{KPSS}})\n",
    "\\]\n",
    "\n",
    "- Ziel: **Minimaler Score**\n",
    "- Begr√ºndung: Kleine ADF-p-Werte + gro√üe KPSS-p-Werte ‚Üí station√§r\n",
    "\n",
    "Der Name und die Serie der ‚Äûbesten Transformation‚Äú werden gespeichert.\n",
    "\n",
    "---\n",
    "\n",
    "###  Rolling-Statistiken und ACF: Visuelle Stationarit√§tspr√ºfung\n",
    "\n",
    "Wir berechnen und visualisieren:\n",
    "\n",
    "- **Rolling Mean** (Gleitender Durchschnitt, Fenster = 20 Tage)\n",
    "- **Rolling Standard Deviation**\n",
    "- **ACF-Werte bei Lag 1 & 2**\n",
    "\n",
    "Ziel: Station√§re Reihen haben **konstante Mittelwerte und Varianzen**, und die ACF f√§llt schnell ab.\n",
    "\n",
    "F√ºr jede Transformation:\n",
    "\n",
    "```python\n",
    "rolling_mean = series.rolling(window=20).mean()\n",
    "rolling_std = series.rolling(window=20).std()\n",
    "acf_vals = acf(series, nlags=2)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "###  ACF- und PACF-Plots\n",
    "\n",
    "F√ºr zwei zentrale Reihen (beste Transformation + Log-Differenz) erstellen wir **ACF- und PACF-Plots mit Konfidenzintervallen**.\n",
    "\n",
    "#### ACF (Autokorrelationsfunktion):\n",
    "Zeigt Korrelation von \\( y_t \\) mit \\( y_{t-k} \\). Wichtig f√ºr MA-Komponente im ARIMA(p, d, q).\n",
    "\n",
    "#### PACF (Partielle Autokorrelationsfunktion):\n",
    "Zeigt \"direkten\" Effekt des Lags \\( k \\) auf \\( y_t \\), ohne Zwischenschritte. Wichtig f√ºr AR-Komponente.\n",
    "\n",
    "Signifikante Lags au√üerhalb der Konfidenzgrenzen (¬±1.96/‚àön) deuten auf relevante Modellbestandteile hin.\n",
    "\n",
    "---\n",
    "\n",
    "##  Fazit Schritt 1\n",
    "\n",
    "- Die Zeitreihe wurde erfolgreich transformiert, um Stationarit√§t zu erreichen.\n",
    "- Durch Kombination von ADF- und KPSS-Tests konnte eine robuste Bewertung vorgenommen werden.\n",
    "- Die **log-differenzierte Zeitreihe** erwies sich als beste Transformation.\n",
    "- ACF- und PACF-Plots legen die Grundlage f√ºr die sp√§tere Modellauswahl (ARIMA-Identifikation).\n",
    "\n",
    "Wir sind nun bereit f√ºr **Modellidentifikation und Parametersch√§tzung**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140b2edd",
   "metadata": {},
   "source": [
    "##  Schritt 2: ARIMA-Modellidentifikation via AIC/BIC\n",
    "\n",
    "Nachdem wir im ersten Schritt die Zeitreihe erfolgreich in eine **station√§re Form** gebracht haben (z.‚ÄØB. durch Log-Differenzierung), k√∂nnen wir nun ein geeignetes ARIMA-Modell identifizieren.\n",
    "\n",
    "---\n",
    "\n",
    "###  Hintergrund: ARIMA(p, d, q)\n",
    "\n",
    "Ein ARIMA-Modell kombiniert drei Komponenten:\n",
    "\n",
    "- **AR (p)**: AutoRegressive-Teil ‚Üí beschreibt, wie der aktuelle Wert von den vorherigen Werten abh√§ngt  \n",
    "- **I (d)**: Integrated-Teil ‚Üí beschreibt, wie viele Differenzierungen notwendig sind, um Stationarit√§t zu erreichen  \n",
    "- **MA (q)**: Moving Average-Teil ‚Üí beschreibt den Einfluss vergangener Sch√§tzfehler (Residuen)\n",
    "\n",
    "Die allgemeine Form eines ARIMA(p,d,q)-Modells ist:\n",
    "\n",
    "\\[\n",
    "y_t = c + \\phi_1 y_{t-1} + \\dots + \\phi_p y_{t-p} + \\theta_1 \\varepsilon_{t-1} + \\dots + \\theta_q \\varepsilon_{t-q} + \\varepsilon_t\n",
    "\\]\n",
    "\n",
    "Dabei ist:\n",
    "- \\( y_t \\): aktueller Wert der Zeitreihe  \n",
    "- \\( \\phi_i \\): AR-Koeffizienten  \n",
    "- \\( \\theta_i \\): MA-Koeffizienten  \n",
    "- \\( \\varepsilon_t \\): wei√üe Rauschkomponente (Zufallsfehler)\n",
    "\n",
    "---\n",
    "\n",
    "###  Ziel: Auswahl des besten (p,d,q)-Modells\n",
    "\n",
    "Um das geeignetste Modell zu finden, wurden alle sinnvollen Kombinationen von p, d und q getestet. Die Auswahl basiert auf:\n",
    "\n",
    "#### Bewertungskriterien:\n",
    "\n",
    "| Kriterium | Ziel      | Formel (vereinfacht)                      | Bestrafung f√ºr Komplexit√§t? |\n",
    "|-----------|-----------|-------------------------------------------|------------------------------|\n",
    "| **AIC**   | Modellg√ºte | \\( \\text{AIC} = -2 \\log(L) + 2k \\)         | Ja (milder)                  |\n",
    "| **BIC**   | Modellg√ºte | \\( \\text{BIC} = -2 \\log(L) + k \\log(n) \\) | Ja (st√§rker)                 |\n",
    "\n",
    "- \\( \\log(L) \\): Log-Likelihood des Modells  \n",
    "- \\( k \\): Anzahl der gesch√§tzten Parameter  \n",
    "- \\( n \\): Anzahl der Beobachtungen\n",
    "\n",
    "Ziel ist es, ein Modell mit m√∂glichst **niedrigem AIC/BIC** zu finden. Dabei gilt:\n",
    "\n",
    "- **AIC** bevorzugt Modelle mit besserer Vorhersagekraft (weniger Bestrafung f√ºr Komplexit√§t)\n",
    "- **BIC** bevorzugt sparsamere Modelle (mehr Bestrafung f√ºr viele Parameter)\n",
    "\n",
    "---\n",
    "\n",
    "###  Beispielausgabe: Top 10 Modelle\n",
    "\n",
    "| p | d | q | AIC     | BIC     |\n",
    "|---|---|---|---------|---------|\n",
    "| 2 | 0 | 2 | 1234.56 | 1250.78 |\n",
    "| 1 | 0 | 1 | 1240.91 | 1251.33 |\n",
    "| 3 | 0 | 0 | 1243.12 | 1257.01 |\n",
    "| 2 | 0 | 1 | 1244.88 | 1258.90 |\n",
    "| 1 | 0 | 2 | 1246.78 | 1260.22 |\n",
    "\n",
    "Aus dieser Tabelle erkennt man, dass das Modell mit **(p=2, d=0, q=2)** den niedrigsten AIC aufweist und damit aktuell das beste Kandidatenmodell ist.\n",
    "\n",
    "---\n",
    "\n",
    "###  Fazit Schritt 2\n",
    "\n",
    "- Durch eine systematische Suche √ºber alle Modellkombinationen wurde das ARIMA-Modell mit der besten Balance aus **G√ºte** und **Komplexit√§t** identifiziert.\n",
    "- Das Kriterium der Wahl war der **Akaike Information Criterion (AIC)**, optional erg√§nzt durch **BIC** zur √úberpr√ºfung.\n",
    "- Dieses Modell kann nun im n√§chsten Schritt gesch√§tzt und validiert werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd62a793",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be8ea32d",
   "metadata": {},
   "source": [
    "##  Schritt 3: Visuelle Forecast-Analyse mit gestuften Trainingsdaten\n",
    "\n",
    "Nachdem wir mit Hilfe von AIC/BIC ein vielversprechendes ARIMA(p,d,q)-Modell ausgew√§hlt haben (z.‚ÄØB. ARIMA(2,0,0)), wollen wir dieses Modell nun **visuell testen**, und zwar in verschiedenen Phasen der Zeitreihe.\n",
    "\n",
    "---\n",
    "\n",
    "###  Ziel: Forecast-G√ºte √ºber mehrere Zeitabschnitte hinweg beurteilen\n",
    "\n",
    "Statt das Modell nur einmal auf die gesamte Serie zu trainieren, wird die Zeitreihe stufenweise aufgeteilt:\n",
    "\n",
    "| Trainingsanteil | Forecastzeitraum | Ziel |\n",
    "|------------------|------------------|------|\n",
    "| 40‚ÄØ%             | n√§chste 20‚ÄØ%     | Fr√ºhprognose auf kurzer Datenbasis  \n",
    "| 60‚ÄØ%             | n√§chste 20‚ÄØ%     | Stabileres Modell  \n",
    "| 80‚ÄØ%             | n√§chste 20‚ÄØ%     | Fast vollst√§ndiges Modell  \n",
    "| 100‚ÄØ%            | +20‚ÄØ% extrapoliert| Finaler Forecast √ºber den Rand hinaus  \n",
    "\n",
    "So k√∂nnen wir grafisch nachvollziehen, **wie stabil und robust** das Modell √ºber verschiedene Zeitabschnitte funktioniert.\n",
    "\n",
    "---\n",
    "\n",
    "###  Methodik\n",
    "\n",
    "1. **Split der Zeitreihe**  \n",
    "   Die Serie wird schrittweise in 4 Etappen unterteilt (40‚ÄØ%, 60‚ÄØ%, 80‚ÄØ%, 100‚ÄØ%).\n",
    "\n",
    "2. **Modellanpassung je Etappe**  \n",
    "   F√ºr jede Teilserie wird das **ARIMA(p,d,q)-Modell** neu gesch√§tzt.\n",
    "\n",
    "3. **Prognoseberechnung**  \n",
    "   F√ºr jede Etappe wird ein Forecast √ºber eine feste L√§nge (z.‚ÄØB. 20‚ÄØ% der Gesamtl√§nge) berechnet.\n",
    "\n",
    "4. **Visualisierung**  \n",
    "   - Blaue Linie = Trainingsdaten  \n",
    "   - Rote Linie = Prognosewerte  \n",
    "   - Graue Linie = Trenngrenze zwischen Training und Forecast  \n",
    "\n",
    "---\n",
    "\n",
    "###  Beispielhafte Plotbeschreibung\n",
    "\n",
    "Wenn z.‚ÄØB. die Zeitreihe 1000 Werte hat, ergibt sich bei 80‚ÄØ% Training und 20‚ÄØ% Forecast:\n",
    "\n",
    "- **Trainingsbereich**: Werte 0 bis 799  \n",
    "- **Forecast**: Werte 800 bis 999  \n",
    "- **Ziel**: Pr√ºfen, ob der Forecast strukturell dem tats√§chlichen Verlauf folgt\n",
    "\n",
    "> ‚ùó **Hinweis**: In der Praxis wurden echte zuk√ºnftige Werte nicht mitgeplottet ‚Äì es geht hier prim√§r um das **Vertrauensverhalten des Modells**, nicht um G√ºtema√üe wie MAPE oder RMSE.\n",
    "\n",
    "---\n",
    "\n",
    "###  Fazit Schritt 3\n",
    "\n",
    "- Durch die gestufte Visualisierung bekommt man ein Gef√ºhl daf√ºr, **wann das ARIMA-Modell stabil prognostiziert** und wo es evtl. versagt.\n",
    "- Diese Methode ist **besonders hilfreich**, um **Overfitting bei kurzer Trainingsphase** zu erkennen.\n",
    "- In Kombination mit der vorherigen AIC/BIC-Auswahl ist das ein robuster Weg, um die Prognosequalit√§t eines Zeitreihenmodells visuell zu pr√ºfen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d66ef",
   "metadata": {},
   "source": [
    "##  Schritt 4: Rolling Forecasts auf Originalskala (zur√ºcktransformiert)\n",
    "\n",
    "Nachdem wir ein geeignetes ARIMA-Modell trainiert und erste Forecasts durchgef√ºhrt haben, folgt nun der **entscheidende Praxisschritt**:  \n",
    "Wir zeigen **rollierende Forecasts** ‚Äì aber diesmal **auf der realen Preisskala**, nicht auf den log-differenzierten Werten.\n",
    "\n",
    "---\n",
    "\n",
    "###  Ziel: Modellg√ºte auf der urspr√ºnglichen Skala beurteilen\n",
    "\n",
    "Das Modell wurde auf **log-transformierten und differenzierten Daten** trainiert, da diese Transformation station√§r macht.  \n",
    "Jetzt kehren wir die Transformation wieder um:\n",
    "\n",
    "1. **Kumulative Summe** der differenzierten Forecasts  \n",
    "2. **Addition des letzten Log-Wertes** vor dem Forecast  \n",
    "3. **Exponentialfunktion**, um von log(X) zur√ºck zu X zu kommen\n",
    "\n",
    "> Ergebnis: Ein Forecast der tats√§chlichen Preisentwicklung ‚Äì in verst√§ndlicher Skalierung (z.‚ÄØB. CHF oder EUR).\n",
    "\n",
    "---\n",
    "\n",
    "###  Methodik\n",
    "\n",
    "#### Rolling Forecast-Stufen:\n",
    "\n",
    "| Trainingsanteil | Forecastzeitraum | Zielsetzung |\n",
    "|-----------------|------------------|-------------|\n",
    "| 40‚ÄØ%            | n√§chste 20‚ÄØ%     | Erste Prognose auf kleiner Datenbasis  \n",
    "| 60‚ÄØ%            | n√§chste 20‚ÄØ%     | Etwas robuster  \n",
    "| 80‚ÄØ%            | n√§chste 20‚ÄØ%     | Fast vollst√§ndige Datenlage  \n",
    "| 100‚ÄØ%           | +20‚ÄØ% extrapoliert| Zukunftsprognose √ºber das bekannte Ende hinaus  \n",
    "\n",
    "#### Vorgehen pro Stufe:\n",
    "\n",
    "- **Modelltraining** auf einem festen Anteil der geloggten Serie\n",
    "- **Forecast** √ºber die n√§chsten 20‚ÄØ% (ab Trainingsende)\n",
    "- **Zur√ºcktransformation**:\n",
    "  - Letzter Log-Wert + kumulierte Differenzen\n",
    "  - Dann: `exp()` anwenden ‚Üí Originalwerte\n",
    "- **Plot-Vergleich**:\n",
    "  - Hellgrau = vollst√§ndige Originalserie\n",
    "  - Rot = Forecast (auf Originalskala)\n",
    "  - Blau (gestrichelt) = Tats√§chliche Entwicklung (sofern bekannt)\n",
    "\n",
    "---\n",
    "\n",
    "###  Visualisierungsziel\n",
    "\n",
    "Ein Plot pro Stufe zeigt:\n",
    "\n",
    "- Wie **gut das Modell zuk√ºnftige Entwicklungen approximiert**\n",
    "- Ob es **Trendwenden erkennt**\n",
    "- Ob es **√ºbersch√§tzt oder untersch√§tzt**\n",
    "- Wo es z.‚ÄØB. **zu langsam reagiert**\n",
    "\n",
    "Die letzte Grafik (100‚ÄØ%) zeigt die echte **Zukunftsprognose** ‚Äì also was wir erwarten w√ºrden, wenn der bisherige Verlauf anhielte.\n",
    "\n",
    "---\n",
    "\n",
    "###  Fazit Schritt 4\n",
    "\n",
    "- Forecasts auf Originalskala erm√∂glichen realistische Bewertungen ‚Äì **\"Was kostet es in CHF?\"** statt \"Wie ist der log-Wert?\"\n",
    "- Die Kombination aus Training in Stufen + zur√ºcktransformierten Forecasts ist ideal zur **Modellvalidierung & Kommunikation**\n",
    "- Die rollierenden Forecastplots sind auch f√ºr **Stakeholder au√üerhalb der Datenanalyse** sehr anschaulich\n",
    "\n",
    "---\n",
    "\n",
    " **Tipp**:  \n",
    "Im n√§chsten Schritt lohnt sich ein Blick auf **Residualanalyse und Diagnostik**, um zu √ºberpr√ºfen, ob Modellannahmen (z.‚ÄØB. wei√üe Rauschen im Fehler) erf√ºllt sind.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be45b73",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4774565a",
   "metadata": {},
   "source": [
    "##  Schritt 5: Residuenanalyse & Modell-Diagnose (ARIMA)\n",
    "\n",
    "Ein statistisches Modell wie ARIMA ist nur dann sinnvoll, wenn seine **Fehler (Residuen)** bestimmte Kriterien erf√ºllen.\n",
    "\n",
    "---\n",
    "\n",
    "###  Ziel der Residuenanalyse:\n",
    "\n",
    "Ein **gutes Modell** hinterl√§sst **\"wei√ües Rauschen\"** ‚Äì also zuf√§llige, unkorrelierte Fehler ohne Muster.  \n",
    "Deshalb pr√ºfen wir in diesem Schritt:\n",
    "\n",
    "1. **Sind die Fehler zuf√§llig verteilt?**\n",
    "2. **Weisen sie Normalverteilung auf?**\n",
    "3. **Gibt es Autokorrelation in den Fehlern?**\n",
    "4. **Sind die Modellparameter signifikant (t-Tests)?**\n",
    "\n",
    "---\n",
    "\n",
    "###  Die 4 diagnostischen Plots\n",
    "\n",
    "| Plot | Beschreibung | Ziel |\n",
    "|------|--------------|------|\n",
    "| **Residuen-Zeitreihe** | Fehler √ºber die Zeit | Keine offensichtlichen Muster, keine Trendlinie |\n",
    "| **Histogramm + Normalverteilung** | Vergleich Fehlerverteilung vs. Normalverteilung | M√∂glichst symmetrisch und glockenf√∂rmig |\n",
    "| **Q-Q-Plot (Quantil-Quantil)** | Pr√ºft Normalverteilung grafisch | Punkte sollten auf Diagonale liegen |\n",
    "| **ACF (Autokorrelationsfunktion)** | Gibt es systematische Fehler √ºber die Zeit? | Alle Werte im Konfidenzintervall (kein Muster) |\n",
    "\n",
    "---\n",
    "\n",
    "###  Statistische Tests\n",
    "\n",
    "#### 1.  Modell-Zusammenfassung (`model_fit.summary()`)\n",
    "\n",
    "- Zeigt **Koeffizienten** und deren **t-Statistiken**\n",
    "- Wenn `|t| > 2` ‚Üí oft statistisch signifikant\n",
    "- AIC/BIC sind ebenfalls enthalten\n",
    "\n",
    "#### 2.  Ljung-Box-Test\n",
    "\n",
    "- Testet, ob Residuen **autokorreliert** sind\n",
    "- Nullhypothese: Keine Autokorrelation vorhanden\n",
    "- Wenn `p > 0.05` ‚Üí kein signifikanter Zusammenhang ‚Üí **gut!**\n",
    "\n",
    "> Beispielausgabe:\n",
    "> ```\n",
    ">                 lb_stat  lb_pvalue\n",
    "> lag\n",
    "> 10          8.764328    0.552399\n",
    "> ```\n",
    "> Interpretation: Bei Lag 10 kein Hinweis auf systematische Fehler (p > 0.05)\n",
    "\n",
    "---\n",
    "\n",
    "###  Fazit Schritt 5\n",
    "\n",
    "- **Best√§tigt die statistische G√ºte** des Modells\n",
    "- Zeigt, ob die Modellannahmen verletzt sind\n",
    "- Grundlage f√ºr Vertrauen in Prognoseergebnisse\n",
    "\n",
    "Wenn **Residuen Muster zeigen**, solltest du dein Modell (p,d,q) noch einmal √ºberdenken.\n",
    "\n",
    "---\n",
    "\n",
    " **N√§chster Schritt (optional):**  \n",
    "Vergleich mit anderen Modellen (z.‚ÄØB. SARIMA, Prophet) oder Forecasting auf echter Preisskala in der Zukunft.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f8a2f6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
