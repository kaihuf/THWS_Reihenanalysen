#  Zeitreihenanalyse Arbeitsschritte

## Einleitung

Ziel dieser Analyse ist es, ein geeignetes ARIMA-Modell zu finden, das den zugrunde liegenden datengenerierenden Prozess einer Finanzzeitreihe (z.‚ÄØB. Aktienkurs) m√∂glichst realit√§tsnah abbildet. Die Analyse erfolgt nach der **Box-Jenkins-Methode**, einem etablierten Verfahren zur Modellierung, Auswahl und Prognose von Zeitreihen.

### Was ist eine Zeitreihe?

Eine **Zeitreihe** ist eine Folge von Beobachtungen, die in regelm√§√üigen Abst√§nden √ºber die Zeit hinweg aufgezeichnet wird ‚Äì beispielsweise t√§gliche Aktienkurse oder monatliche Arbeitslosenzahlen. Der Zweck der Zeitreihenanalyse ist es, **Strukturen wie Trends, Saisonalit√§t und Autokorrelationen zu identifizieren**, um pr√§zise Prognosen f√ºr zuk√ºnftige Werte zu erstellen.

### Warum Box-Jenkins?

Die **Box-Jenkins-Methode** konzentriert sich auf die Klasse der **ARIMA-Modelle (AutoRegressive Integrated Moving Average)**. Diese Modelle sind besonders flexibel und leistungsf√§hig, wenn es darum geht, komplexe Zeitreihenprozesse ohne klare saisonale Struktur zu modellieren. Die Methodik umfasst drei zentrale Schritte:

1. **Identifikation** des Modells (z.‚ÄØB. Wahl der ARIMA-Ordnung),
2. **Sch√§tzung** der Modellparameter,
3. **Diagnosepr√ºfung** der Modellg√ºte.


### Ziel dieser Arbeit

Wir m√∂chten ein automatisiertes Analyseverfahren entwickeln, das:

- eine Zeitreihe auf Stationarit√§t pr√ºft und ggf. transformiert,
- verschiedene ARIMA-Modelle testet und bewertet,
- auf Basis statistischer Kriterien das geeignetste Modell ausw√§hlt,
- eine Rolling Forecast durchf√ºhrt und   
- die Ergebnisse visuell und statistisch bewertet.

Zus√§tzlich ber√ºcksichtigen wir **Modellvalidierung** (z.‚ÄØB. Residuenanalyse), **t-Tests der Parameter**, sowie die **Generierung von Prognosen**.

---

##  Zeitreihenanalyse ‚Äì Schritt 1: Datenvorbereitung & Stationarit√§tspr√ºfung

### √úberblick: Warum ist Stationarit√§t wichtig?

Ein zentrales Ziel bei der Zeitreihenanalyse mit ARIMA-Modellen ist die Identifikation und Modellierung des zugrunde liegenden stochastischen Prozesses. ARIMA-Modelle (AutoRegressive Integrated Moving Average) setzen voraus, dass die analysierte Zeitreihe **station√§r** ist.

**Stationarit√§t** bedeutet, dass die statistischen Eigenschaften der Zeitreihe ‚Äì insbesondere der Erwartungswert, die Varianz und die Autokorrelation ‚Äì √ºber die Zeit hinweg konstant bleiben. Wenn dies nicht gegeben ist (z.‚ÄØB. bei Trends, saisonalen Effekten oder Heteroskedastizit√§t), kann das Modell fehlspezifiziert werden.

---

###  Datenimport & Visualisierung der Originalreihe

Wir importieren zun√§chst die Aktienkurs-Zeitreihe von Samsung (‚ÄûAdjusted Close‚Äú-Preise), konvertieren das Datum in ein geeignetes Format und erstellen eine erste Visualisierung der urspr√ºnglichen, **nicht transformierten** Zeitreihe.


**Beobachtung:**  
Die urspr√ºngliche Zeitreihe zeigt visuell einen starken Trend ‚Äì sowohl auf- als auch abw√§rtsgerichtet in unterschiedlichen Phasen. Solche Trends deuten auf **Nichtstationarit√§t** hin.

---

###  Stationarit√§tstests: ADF und KPSS

Um Stationarit√§t statistisch zu pr√ºfen, wenden wir zwei komplement√§re Tests an:

#### üîπ Augmented Dickey-Fuller-Test (ADF)
- **Nullhypothese (H‚ÇÄ):** Die Zeitreihe hat eine Einheitwurzel ‚Üí *nicht station√§r*
- **Alternativhypothese (H‚ÇÅ):** Stationarit√§t liegt vor
- Wir lehnen H‚ÇÄ ab, wenn der **p-Wert < 0.05**

**Testformel:**

$$
\Delta y_t = \alpha + \beta t + \gamma y_{t-1} + \sum_{i=1}^{p} \delta_i \Delta y_{t-i} + \varepsilon_t
$$


#### üîπ KPSS-Test (Kwiatkowski-Phillips-Schmidt-Shin)
- **Nullhypothese (H‚ÇÄ):** Die Zeitreihe ist station√§r (gegen Trendstationarit√§t)
- **Alternativhypothese (H‚ÇÅ):** Die Zeitreihe ist nicht station√§r
- Wir behalten H‚ÇÄ bei, wenn **p-Wert > 0.05**

#### üîπ Phillips-Perron-Test (PP)

Der Phillips-Perron-Test ist eine weitere Methode zur Pr√ºfung auf Einheitwurzeln und √§hnelt dem ADF, ber√ºcksichtigt aber heteroskedastische und serielle Korrelation in den Residuen auf flexible Weise.

- **Nullhypothese (H‚ÇÄ):** Die Zeitreihe besitzt eine Einheitwurzel ‚Üí *nicht station√§r*  
- **Alternativhypothese (H‚ÇÅ):** Stationarit√§t liegt vor  
- Wir lehnen H‚ÇÄ ab, wenn der **p-Wert < 0.05**

**Testidee:**  
PP erweitert das klassische Dickey‚ÄìFuller-Modell  
$
\Delta y_t = \alpha + \beta t + \gamma\,y_{t-1} + \varepsilon_t
$
um eine semi-nonparametrische Korrektur der Teststatistik, um m√∂gliche Autokorrelation und Heteroskedastizit√§t in den Fehlern $ \varepsilon_t $ zu entfernen, ohne explizit verz√∂gerte Differenzen einzuf√ºgen.

**Teststatistik:**  
$$
Z_{\rho} = T\big(\hat{\rho}-1\big) - \tfrac{1}{2} \;\frac{\hat{\sigma}^2_{\Delta\varepsilon}}{\hat{\sigma}^2_{\varepsilon}}
$$  
wobei  

$\hat{\rho}$ der gesch√§tzte AR-Parameter ist,  
- $\hat{\sigma}^2_{\varepsilon}$ die Varianz der Roh-Residuen und  
- $\hat{\sigma}^2_{\Delta\varepsilon}$ die Varianz der Residuen-Differenzen (korrigiert um serielle Korrelation)

**Vorteil gegen√ºber ADF:**  
Keine manuelle Wahl der Verz√∂gerungen \(p\) n√∂tig ‚Äì die Korrektur erfolgt implizit √ºber eine Newey-West-artige Sch√§tzung.

**Praxis-Tipp:**  
Vergleiche PP- und ADF-Ergebnisse: Wenn beide zu √§hnlichen Entscheidungen kommen, erh√∂hst Du das Vertrauen in das Testergebnis.

**Kombination beider Tests:**  
Sie erm√∂glicht eine robustere Beurteilung, da sie aus zwei Perspektiven pr√ºfen.



---

###  Transformationen zur Erreichung von Stationarit√§t

Um die urspr√ºngliche Reihe in eine station√§re zu √ºberf√ºhren, wenden wir mehrere Transformationen an ‚Äì jede mit einem spezifischen Ziel:

| Transformation                        | Zweck |
|--------------------------------------|-------|
| **1. Differenzierung**:  $$ y_t - y_{t-1} $$  | Entfernt lineare Trends |
| **2. Differenzierung**: $$ (y_t - y_{t-1}) - (y_{t-1} - y_{t-2}) $$ | Entfernt quadratische/komplexere Trends |
| **Logarithmierung**: $$ \log(y_t) $$ | Stabilisiert Varianz (z.‚ÄØB. bei exponentiellem Wachstum) |
| **Log-Differenz**: $$ \log(y_t) - \log(y_{t-1}) $$ | Kombiniert Trendentfernung und Varianzstabilisierung |
| **Moving Average Residuum**: $$ y_t - \overline{y}_{t,window} $$ | Entfernt gleitenden Mittelwert (Trend) |
| **Exponentielle Gl√§ttung** | Entfernt Trend mit h√∂herem Gewicht auf j√ºngere Werte |
| **HP-Filter (Hodrick-Prescott)** | Trennt Trend- und Zykluskomponente der Reihe |

Nach jeder Transformation f√ºhren wir erneut ADF- und KPSS-Tests durch, um den Erfolg zu bewerten.

---

###  Visualisierung der Transformationen

Die transformierten Zeitreihen werden grafisch dargestellt ‚Äì inklusive der jeweiligen Testergebnisse (ADF & KPSS) in Textboxen.

**Beispiel:**

```text
ADF p = 0.021 ‚Üí Station√§r  
KPSS p = 0.08 ‚Üí Station√§r
```

Dies erlaubt eine schnelle visuelle und numerische Bewertung jeder Transformation.

---

###  Auswahl der besten Transformation

Zur systematischen Auswahl verwenden wir eine **Scoring-Funktion**, die beide Tests kombiniert:

$
\text{Stationarit√§tsscore} = p_{\text{ADF}} + (1 - p_{\text{KPSS}})
$

- Ziel: **Minimaler Score**
- Begr√ºndung: Kleine ADF-p-Werte + gro√üe KPSS-p-Werte ‚Üí station√§r

Der Name und die Serie der ‚Äûbesten Transformation‚Äú werden gespeichert.

---

###  Rolling-Statistiken und ACF: Visuelle Stationarit√§tspr√ºfung

Wir berechnen und visualisieren:

- **Rolling Mean** (Gleitender Durchschnitt, Fenster = 20 Tage)
- **Rolling Standard Deviation**
- **ACF-Werte bei Lag 1 & 2**

Ziel: Station√§re Reihen haben **konstante Mittelwerte und Varianzen**, und die ACF f√§llt schnell ab.

F√ºr jede Transformation:

```python
rolling_mean = series.rolling(window=20).mean()
rolling_std = series.rolling(window=20).std()
acf_vals = acf(series, nlags=2)
```

---

###  ACF- und PACF-Plots

F√ºr zwei zentrale Reihen (beste Transformation + Log-Differenz) erstellen wir **ACF- und PACF-Plots mit Konfidenzintervallen**.

#### ACF (Autokorrelationsfunktion):
Zeigt Korrelation von $ y_t $ mit $ y_{t-k} $. Wichtig f√ºr MA-Komponente im ARIMA(p, d, q).

#### PACF (Partielle Autokorrelationsfunktion):
Zeigt "direkten" Effekt des Lags $ k $ auf $ y_t $, ohne Zwischenschritte. Wichtig f√ºr AR-Komponente.

Signifikante Lags au√üerhalb der Konfidenzgrenzen $ ¬±1.96/‚àön $ deuten auf relevante Modellbestandteile hin.

---

##  Fazit Schritt 1

- Die Zeitreihe wurde erfolgreich transformiert, um Stationarit√§t zu erreichen.
- Durch Kombination von ADF- und KPSS-Tests konnte eine robuste Bewertung vorgenommen werden.
- Die **log-differenzierte Zeitreihe** erwies sich als beste Transformation.
- ACF- und PACF-Plots legen die Grundlage f√ºr die sp√§tere Modellauswahl (ARIMA-Identifikation).

Wir sind nun bereit f√ºr **Modellidentifikation und Parametersch√§tzung**.

##  Schritt 2: ARIMA-Modellidentifikation via AIC/BIC

Nachdem wir im ersten Schritt die Zeitreihe erfolgreich in eine **station√§re Form** gebracht haben (z.‚ÄØB. durch Log-Differenzierung), k√∂nnen wir nun ein geeignetes ARIMA-Modell identifizieren.

---

###  Hintergrund: ARIMA(p, d, q)

Ein ARIMA-Modell kombiniert drei Komponenten:

- **AR (p)**: AutoRegressive-Teil ‚Üí beschreibt, wie der aktuelle Wert von den vorherigen Werten abh√§ngt  
- **I (d)**: Integrated-Teil ‚Üí beschreibt, wie viele Differenzierungen notwendig sind, um Stationarit√§t zu erreichen  
- **MA (q)**: Moving Average-Teil ‚Üí beschreibt den Einfluss vergangener Sch√§tzfehler (Residuen)

Die allgemeine Form eines ARIMA(p,d,q)-Modells ist:

$$
\Delta y_t = \alpha + \beta t + \gamma y_{t-1} + \sum_{i=1}^{p} \delta_i \Delta y_{t-i} + \varepsilon_t
$$


Dabei ist:
- $ y_t $: aktueller Wert der Zeitreihe  
- $ \phi_i $: AR-Koeffizienten  
- $ \theta_i $: MA-Koeffizienten  
- $ \varepsilon_t $: wei√üe Rauschkomponente (Zufallsfehler)

---

###  Ziel: Auswahl des besten (p,d,q)-Modells

Um das geeignetste Modell zu finden, wurden alle sinnvollen Kombinationen von p, d und q getestet. Die Auswahl basiert auf:

#### Bewertungskriterien:

| Kriterium | Ziel      | Formel (vereinfacht)                      | Bestrafung f√ºr Komplexit√§t? |
|-----------|-----------|-------------------------------------------|------------------------------|
| **AIC**   | Modellg√ºte | $$ \text{AIC} = -2 \log(L) + 2k \ $$         | Ja (milder)                  |
| **BIC**   | Modellg√ºte | $$ \text{BIC} = -2 \log(L) + k \log(n) \ $$ | Ja (st√§rker)                 |

- $ \log(L) $: Log-Likelihood des Modells  
- $ k $: Anzahl der gesch√§tzten Parameter  
- $ n $: Anzahl der Beobachtungen

Ziel ist es, ein Modell mit m√∂glichst **niedrigem AIC/BIC** zu finden. Dabei gilt:

- **AIC** bevorzugt Modelle mit besserer Vorhersagekraft (weniger Bestrafung f√ºr Komplexit√§t)
- **BIC** bevorzugt sparsamere Modelle (mehr Bestrafung f√ºr viele Parameter)

---

###  Beispielausgabe: Top 10 Modelle

| p | d | q | AIC     | BIC     |
|---|---|---|---------|---------|
| 2 | 0 | 2 | 1234.56 | 1250.78 |
| 1 | 0 | 1 | 1240.91 | 1251.33 |
| 3 | 0 | 0 | 1243.12 | 1257.01 |
| 2 | 0 | 1 | 1244.88 | 1258.90 |
| 1 | 0 | 2 | 1246.78 | 1260.22 |

Aus dieser Tabelle erkennt man, dass das Modell mit **(p=2, d=0, q=2)** den niedrigsten AIC aufweist und damit aktuell das beste Kandidatenmodell ist.

---

###  Fazit Schritt 2

- Durch eine systematische Suche √ºber alle Modellkombinationen wurde das ARIMA-Modell mit der besten Balance aus **G√ºte** und **Komplexit√§t** identifiziert.
- Das Kriterium der Wahl war der **Akaike Information Criterion (AIC)**, optional erg√§nzt durch **BIC** zur √úberpr√ºfung.
- Dieses Modell kann nun im n√§chsten Schritt gesch√§tzt und validiert werden.


##  Schritt 3: Visuelle Forecast-Analyse mit gestuften Trainingsdaten

Nachdem wir mit Hilfe von AIC/BIC ein vielversprechendes ARIMA(p,d,q)-Modell ausgew√§hlt haben (z.‚ÄØB. ARIMA(2,0,0)), wollen wir dieses Modell nun **visuell testen**, und zwar in verschiedenen Phasen der Zeitreihe.

---

###  Ziel: Forecast-G√ºte √ºber mehrere Zeitabschnitte hinweg beurteilen

Statt das Modell nur einmal auf die gesamte Serie zu trainieren, wird die Zeitreihe stufenweise aufgeteilt:

| Trainingsanteil | Forecastzeitraum | Ziel |
|------------------|------------------|------|
| 40‚ÄØ%             | n√§chste 15‚ÄØ%     | Fr√ºhprognose auf kurzer Datenbasis  
| 55‚ÄØ%             | n√§chste 15‚ÄØ%     | Stabileres Modell  
| 70‚ÄØ%             | n√§chste 15‚ÄØ%     | Fast vollst√§ndiges Modell  
| 85‚ÄØ%            | n√§chste 15% | Fast vollst√§ndiges Modell 
| 100‚ÄØ%            | +15‚ÄØ% extrapoliert| Finaler Forecast √ºber den Rand hinaus  

So k√∂nnen wir grafisch nachvollziehen, **wie stabil und robust** das Modell √ºber verschiedene Zeitabschnitte funktioniert.

---

###  Methodik

1. **Split der Zeitreihe**  
   Die Serie wird schrittweise in 5 Etappen unterteilt (40‚ÄØ%, 55‚ÄØ%, 70‚ÄØ%, 85‚ÄØ%, 100 %).

2. **Modellanpassung je Etappe**  
   F√ºr jede Teilserie wird das **ARIMA(p,d,q)-Modell** neu gesch√§tzt.

3. **Prognoseberechnung**  
   F√ºr jede Etappe wird ein Forecast √ºber eine feste L√§nge (z.‚ÄØB. 15‚ÄØ% der Gesamtl√§nge) berechnet.

4. **Visualisierung**  
  

---

###  Beispielhafte Plotbeschreibung

Wenn z.‚ÄØB. die Zeitreihe 1000 Werte hat, ergibt sich bei 80‚ÄØ% Training und 20‚ÄØ% Forecast:

- **Trainingsbereich**: Werte 0 bis 799  
- **Forecast**: Werte 800 bis 999  
- **Ziel**: Pr√ºfen, ob der Forecast strukturell dem tats√§chlichen Verlauf folgt


---

###  Fazit Schritt 3

- Durch die gestufte Visualisierung bekommt man ein Gef√ºhl daf√ºr, **wann das ARIMA-Modell stabil prognostiziert** und wo es evtl. versagt.
- Diese Methode ist **besonders hilfreich**, um **Overfitting bei kurzer Trainingsphase** zu erkennen.
- In Kombination mit der vorherigen AIC/BIC-Auswahl ist das ein robuster Weg, um die Prognosequalit√§t eines Zeitreihenmodells visuell zu pr√ºfen.



## Darstellungen unserer Vorhersagen

### **Daimler**
![Daimler](/data_analytics/ergebnisse/daimler_unified_time_series_stock_price_plot.png)

### **Microsoft**
![Microsoft](/data_analytics/ergebnisse/microsoft_unified_time_series_stock_price_plot.png)

### **Samsung**
![Samsung](/data_analytics/ergebnisse/samsung_unified_time_series_stock_price_plot.png)


##  Schritt 4: Rolling Forecasts auf Originalskala (zur√ºcktransformiert)

Nachdem wir ein geeignetes ARIMA-Modell trainiert und erste Forecasts durchgef√ºhrt haben, folgt nun der **entscheidende Praxisschritt**:  
Wir zeigen **rollierende Forecasts** ‚Äì aber diesmal **auf der realen Preisskala**, nicht auf den log-differenzierten Werten.

---

###  Ziel: Modellg√ºte auf der urspr√ºnglichen Skala beurteilen

Das Modell wurde auf **log-transformierten und differenzierten Daten** trainiert, da diese Transformation station√§r macht.  
Jetzt kehren wir die Transformation wieder um:

1. **Kumulative Summe** der differenzierten Forecasts  
2. **Addition des letzten Log-Wertes** vor dem Forecast  
3. **Exponentialfunktion**, um von $ log(X) $ zur√ºck zu $ X $ zu kommen

> Ergebnis: Ein Forecast der tats√§chlichen Preisentwicklung 

---

###  Methodik

#### Rolling Forecast-Stufen:

| Trainingsanteil | Forecastzeitraum  | Zielsetzung |
|-----------------|-------------------|-------------|
| 40‚ÄØ%            | n√§chste 15‚ÄØ%      | Erste Prognose auf kleiner Datenbasis  
| 55‚ÄØ%            | n√§chste 15‚ÄØ%      | Etwas robuster  
| 70‚ÄØ%            | n√§chste 15‚ÄØ%      | Fast vollst√§ndige Datenlage  
| 85‚ÄØ%            | n√§chste 15 %      | Fast vollst√§ndige Datenlage 
| 100‚ÄØ%           | +15‚ÄØ% extrapoliert| Finaler Forecast √ºber den Rand hinaus   

#### Vorgehen pro Stufe:

- **Modelltraining** auf einem festen Anteil der geloggten Serie
- **Forecast** √ºber die n√§chsten 15‚ÄØ% (ab Trainingsende)
- **Zur√ºcktransformation**:
  - Letzter Log-Wert + kumulierte Differenzen
  - Dann: `exp()` anwenden ‚Üí Originalwerte
- **Plot-Vergleich**:
  - Hellgrau = vollst√§ndige Originalserie
  - Rot = Forecast (auf Originalskala)
  - Blau (gestrichelt) = Tats√§chliche Entwicklung (sofern bekannt)

---

###  Visualisierungsziel

Ein Plot pro Stufe zeigt:

- Wie **gut das Modell zuk√ºnftige Entwicklungen approximiert**
- Ob es **Trendwenden erkennt**
- Ob es **√ºbersch√§tzt oder untersch√§tzt**
- Wo es z.‚ÄØB. **zu langsam reagiert**

Die letzte Grafik (100‚ÄØ%) zeigt die echte **Zukunftsprognose** ‚Äì also was wir erwarten w√ºrden, wenn der bisherige Verlauf anhielte.

---



---

 
## Schritt 5: Residuenanalyse & Modell-Diagnose (ARIMA)

Ein statistisches Modell wie ARIMA ist nur dann sinnvoll, wenn seine **Fehler (Residuen)** bestimmten Annahmen gen√ºgen.  
Die Analyse der Residuen zeigt uns, ob unser Modell sauber gearbeitet hat ‚Äì oder ob es noch systematische Muster oder Schw√§chen gibt.

---

### Ziel der Residuenanalyse:

Ein gutes Modell hinterl√§sst **"wei√ües Rauschen"** ‚Äì das hei√üt:

- Fehler sind zuf√§llig verteilt
- Es gibt **keine Autokorrelation**
- Die Fehler sind **normalverteilt**
- Die Varianz ist konstant
- Der Mittelwert der Fehler ist nahe **null**

---

### Wichtige Tests zur Residuenanalyse

#### 1. Ljung-Box Test

Der Ljung-Box-Test pr√ºft, ob es **Autokorrelation** in den Residuen gibt ‚Äì also ob heutige Fehler mit vergangenen Fehlern zusammenh√§ngen.

- **Nullhypothese**: Es gibt **keine Autokorrelation** ‚Üí gut!
- **Interpretation**:  
  - Wenn **p-Wert > 0.05** ‚Üí Fehler sind unkorreliert (‚úì)
  - Wenn **p-Wert ‚â§ 0.05** ‚Üí Es gibt Korrelation (‚úó), Modell evtl. unzureichend

#### 2. Jarque-Bera Test

Der Jarque-Bera-Test pr√ºft, ob die Residuen **normalverteilt** sind.

- **Nullhypothese**: Die Residuen sind **normalverteilt**
- **Interpretation**:  
  - Wenn **p-Wert > 0.05** ‚Üí Normalverteilung gegeben (‚úì)
  - Wenn **p-Wert ‚â§ 0.05** ‚Üí Abweichung von Normalverteilung (‚úó), Modellfehler oder Transformation n√∂tig

---

### Weitere Plots zur Diagnose

| Plot                         | Beschreibung                                 | Ziel                                         |
|------------------------------|----------------------------------------------|----------------------------------------------|
| **Residuen-Zeitreihe**       | Fehler √ºber die Zeit                         | Keine offensichtlichen Muster, keine Trends |
| **Histogramm + Normalverteilung** | Vergleich Fehlerverteilung vs. Normalverteilung | M√∂glichst symmetrisch und glockenf√∂rmig     |
| **Q-Q-Plot (Quantil-Quantil)** | Pr√ºft Normalverteilung grafisch              | Punkte sollten auf Diagonale liegen         |

---

### Statistische Modell-Zusammenfassung (`model_fit.summary()`)

- Zeigt **Koeffizienten** mit **t-Statistiken**
- Wenn `|t| > 2`, dann sind die Parameter h√§ufig **statistisch signifikant**
- AIC und BIC helfen bei Modellvergleich

---

## RESIDUENANALYSE - ZUSAMMENFASSUNG

**SAMSUNG:**  
- Ljung-Box Test (p-Wert): 0.9722  
  ‚Üí ‚úì Keine Autokorrelation  
- Jarque-Bera Test (p-Wert): 0.0000  
  ‚Üí ‚úó Keine Normalverteilung  
- Residuen Mittelwert: 0.000002  
- Residuen Std: 0.0215  

**DAIMLER:**  
- Ljung-Box Test (p-Wert): 0.0470  
  ‚Üí ‚úó Autokorrelation vorhanden  
- Jarque-Bera Test (p-Wert): 0.0000  
  ‚Üí ‚úó Keine Normalverteilung  
- Residuen Mittelwert: 0.000214  
- Residuen Std: 0.0213  

**MICROSOFT:**  
- Ljung-Box Test (p-Wert): 0.0000  
  ‚Üí ‚úó Autokorrelation vorhanden  
- Jarque-Bera Test (p-Wert): 0.0000  
  ‚Üí ‚úó Keine Normalverteilung  
- Residuen Mittelwert: 0.000447  
- Residuen Std: 0.0212  

---

## INTERPRETATION

- **Samsung:**  
  Residuen scheinen unkorreliert, aber nicht normalverteilt. Das Modell beschreibt die Dynamik gut, k√∂nnte aber bei Verteilung der Fehler verbessert werden (z.‚ÄØB. durch Transformationen oder robustere Verfahren).

- **Daimler & Microsoft:**  
  Beide Modelle zeigen **Autokorrelation** und **keine Normalverteilung** der Residuen. Das deutet darauf hin, dass hier noch **systematische Muster** in den Daten nicht erfasst wurden.  
  ‚Üí Empfehlung: Modellierung (p,d,q) √ºberdenken oder alternative Modelle wie SARIMA oder GARCH in Betracht ziehen.

---

## Fazit Schritt 5

- Die **Residuenanalyse zeigt**, ob die statistischen Annahmen des ARIMA-Modells erf√ºllt sind.
- Nur wenn die Fehler zuf√§llig, unkorreliert und normalverteilt sind, ist die Prognose statistisch **zuverl√§ssig**.
- Abweichungen (wie bei Daimler/Microsoft) zeigen: Modell ggf. **nicht ausreichend angepasst**.

---

