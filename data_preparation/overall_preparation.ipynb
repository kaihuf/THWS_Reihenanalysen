{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inhaltsverzeichnis des Skripts:\n",
    "\n",
    "[[_TOC_]]\n",
    "\n",
    "---\n",
    "\n",
    "### Vorliegende Datentyp:\n",
    "\n",
    "**quantitative Daten auf Kardinalskala**\n",
    "\n",
    "*Vorliegende Columns:*\n",
    "\n",
    "- **Date:** Datum\n",
    "- **Open:** Eröffnungskurs\n",
    "- **High:** Höchstkurs\n",
    "- **Low:** Tiefkurs\n",
    "- **Close:** Schlusskurs\n",
    "- **Volume:** Handelsvolumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#--------------- benötigten Librarys ------------------#\n",
    "########################################################\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download und Speicherung der Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_stock_data(ticker_symbol, time_period, data_folder=\"../data\"):\n",
    "    \"\"\"\n",
    "    Lädt Aktiendaten von Yahoo Finance herunter und speichert sie als CSV.\n",
    "    \n",
    "    Args:\n",
    "        ticker_symbol (str): Das Ticker-Symbol der Aktie (z.B. \"MSFT\" für Microsoft)\n",
    "        time_period (str): Der Zeitraum für die Daten (z.B. \"5y\", \"1mo\", \"max\")\n",
    "        data_folder (str): Pfad zum Datenordner, standardmäßig \"../data\" (eine Ebene hoch und dann in 'data')\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Der heruntergeladene Datensatz\n",
    "        pandas.DataFrame: Statistische Zusammenfassung\n",
    "    \"\"\"\n",
    "    \n",
    "    # Erstelle Dateinamen aus dem Ticker-Symbol\n",
    "    file_name = f\"{ticker_symbol.lower()}_aktien_daten.csv\"\n",
    "    csv_file_location = os.path.join(data_folder, file_name)\n",
    "\n",
    "    # Ticker-Objekt abrufen\n",
    "    stock = yf.Ticker(ticker_symbol)\n",
    "    \n",
    "    # Historische Daten herunterladen\n",
    "    hist_data = stock.history(period=time_period)\n",
    "\n",
    "    # Entferne die Spalten 'Dividends' und 'Stock Splits'\n",
    "    columns_to_drop = ['Dividends', 'Stock Splits']\n",
    "    hist_data = hist_data.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    # Daten als CSV speichern\n",
    "    hist_data.to_csv(csv_file_location)\n",
    "    print(f\"Daten wurden in {csv_file_location} gespeichert.\")\n",
    "\n",
    "    # Erste Spalte zu Datum konvertieren und als Index setzen\n",
    "    hist_data = hist_data.reset_index()\n",
    "    hist_data['Date'] = pd.to_datetime(hist_data['Date']).dt.normalize()  # Entfernt die Uhrzeit\n",
    "    hist_data = hist_data.set_index('Date')\n",
    "    hist_data.to_csv(csv_file_location, date_format='%Y-%m-%d')\n",
    "\n",
    "    # Konvertiere alle numerischen Spalten zu Float\n",
    "    for col in hist_data.columns:\n",
    "        hist_data[col] = pd.to_numeric(hist_data[col], errors='coerce')\n",
    "\n",
    "    # Allgemeine Infos\n",
    "    print(f\"+{'-'*48}+\")\n",
    "    print(f\"|{'Allgemeine Informationen der Aktien-Daten':^48}|\")\n",
    "    print(f\"+{'-'*48}+ \\n\")\n",
    "    hist_data.info()\n",
    "    \n",
    "    # Statistische Zusammenfassung\n",
    "    data_zusammenfassung = hist_data.describe()\n",
    "    print(f\"\\n\\n\")\n",
    "    print(f\"+{'-'*48}+\")\n",
    "    print(f\"|{'Statistische Zusammenfassung der Aktien-Daten':^48}|\")\n",
    "    print(f\"+{'-'*48}+ \\n\")\n",
    "    print(data_zusammenfassung)\n",
    "\n",
    "    return hist_data, data_zusammenfassung, csv_file_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erste Analyse des Datensatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "def analyze_stock_data(file_path):\n",
    "    \"\"\"\n",
    "    Führt eine umfassende Analyse eines Aktiendatensatzes aus einer CSV-Datei durch.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Pfad zur CSV-Datei mit den Aktiendaten\n",
    "        \n",
    "    Returns:\n",
    "        dict: Ein Dictionary mit verschiedenen Analyseergebnissen\n",
    "    \"\"\"\n",
    "    # Überprüfe, ob die Datei existiert\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"FEHLER: Die Datei {file_path} existiert nicht.\")\n",
    "        return None\n",
    "    \n",
    "    # Lade die Daten\n",
    "    try:\n",
    "        # Versuche, die Daten zu laden und das Datum als Index zu setzen\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Prüfe, ob 'Date' oder ein ähnliches Datumsfeld vorhanden ist\n",
    "        date_columns = [col for col in df.columns if 'date' in col.lower() or 'datum' in col.lower()]\n",
    "        \n",
    "        if date_columns:\n",
    "            # Verwende die erste gefundene Datumsspalte\n",
    "            date_col = date_columns[0]\n",
    "            df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "            df = df.set_index(date_col)\n",
    "        elif 'Unnamed: 0' in df.columns:\n",
    "            # Typischer Fall bei aus yfinance exportierten CSV-Dateien\n",
    "            df['Date'] = pd.to_datetime(df['Unnamed: 0'], errors='coerce')\n",
    "            df = df.drop(columns=['Unnamed: 0'])\n",
    "            df = df.set_index('Date')\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"FEHLER beim Laden der Datei: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Ausgabe des Dateinamens und grundlegende Informationen\n",
    "    file_name = os.path.basename(file_path)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ANALYSE DER DATEI: {file_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # 1. Grundlegende Informationen\n",
    "    print(\"\\n1. GRUNDLEGENDE INFORMATIONEN\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Zeitraum: {df.index.min()} bis {df.index.max()}\")\n",
    "    print(f\"Anzahl der Datenpunkte: {len(df)}\")\n",
    "    print(f\"Anzahl der Variablen: {df.shape[1]}\")\n",
    "    \n",
    "    # Speichere die Analyse-Ergebnisse\n",
    "    results = {\n",
    "        'file_name': file_name,\n",
    "        'data_points': len(df),\n",
    "        'variables': df.shape[1],\n",
    "        'period': {\n",
    "            'start': df.index.min(),\n",
    "            'end': df.index.max(),\n",
    "            'days': (df.index.max() - df.index.min()).days\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 2. Datentypanalyse\n",
    "    print(\"\\n2. DATENTYPEN\")\n",
    "    print(f\"{'='*50}\")\n",
    "    dtypes = df.dtypes\n",
    "    print(dtypes)\n",
    "    \n",
    "    results['data_types'] = {col: str(dtype) for col, dtype in dtypes.items()}\n",
    "    \n",
    "    # 3. Fehlende Werte-Analyse\n",
    "    print(\"\\n3. FEHLENDE WERTE\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Anzahl und Prozentsatz der fehlenden Werte\n",
    "    na_count = df.isna().sum()\n",
    "    na_percent = 100 * na_count / len(df)\n",
    "    \n",
    "    # Kombiniere die Ergebnisse\n",
    "    na_summary = pd.DataFrame({\n",
    "        'Fehlende Werte': na_count,\n",
    "        'Prozent fehlend': na_percent\n",
    "    })\n",
    "    \n",
    "    print(na_summary)\n",
    "    \n",
    "    # Gesamtanzahl der fehlenden Werte\n",
    "    total_missing = na_count.sum()\n",
    "    total_missing_percent = 100 * total_missing / (len(df) * df.shape[1])\n",
    "    \n",
    "    print(f\"\\nGesamtanzahl fehlender Werte: {total_missing} ({total_missing_percent:.2f}%)\")\n",
    "    \n",
    "    results['missing_values'] = {\n",
    "        'per_column': {col: {'count': int(count), 'percent': float(percent)} \n",
    "                      for col, count, percent in zip(na_summary.index, na_count, na_percent)},\n",
    "        'total': {\n",
    "            'count': int(total_missing),\n",
    "            'percent': float(total_missing_percent)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 4. Deskriptive Statistik\n",
    "    print(\"\\n4. DESKRIPTIVE STATISTIK\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Sinnvolle Statistiken für numerische Daten\n",
    "    desc_stats = df.describe().T\n",
    "    \n",
    "    # Füge zusätzliche Statistiken hinzu\n",
    "    desc_stats['Var'] = df.var()\n",
    "    desc_stats['Skewness'] = df.skew()\n",
    "    desc_stats['Kurtosis'] = df.kurtosis()\n",
    "    \n",
    "    print(desc_stats)\n",
    "    \n",
    "    results['descriptive_stats'] = desc_stats.to_dict()\n",
    "    \n",
    "    # 5. Untersuchung auf Ausreißer\n",
    "    print(\"\\n5. AUSREISSERANALYSE\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Z-Score-Methode zur Identifizierung von Ausreißern\n",
    "    outliers = {}\n",
    "    \n",
    "    for col in df.select_dtypes(include=np.number).columns:\n",
    "        z_scores = np.abs(stats.zscore(df[col].dropna()))\n",
    "        outliers_count = (z_scores > 3).sum()  # Werte, die mehr als 3 Standardabweichungen vom Mittelwert entfernt sind\n",
    "        outliers_percent = 100 * outliers_count / len(z_scores)\n",
    "        \n",
    "        outliers[col] = {\n",
    "            'count': int(outliers_count),\n",
    "            'percent': float(outliers_percent)\n",
    "        }\n",
    "        \n",
    "        print(f\"Spalte '{col}': {outliers_count} Ausreißer ({outliers_percent:.2f}%)\")\n",
    "    \n",
    "    results['outliers'] = outliers\n",
    "    \n",
    "    # 6. Korrelationsanalyse\n",
    "    print(\"\\n6. KORRELATIONSANALYSE\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    try:\n",
    "        corr = df.corr(method='pearson')\n",
    "        print(corr)\n",
    "        \n",
    "        # Visualisiere die Korrelationsmatrix (optional)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "        plt.title('Korrelationsmatrix der Aktienparameter')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        results['correlation'] = corr.to_dict()\n",
    "    except Exception as e:\n",
    "        print(f\"Konnte keine Korrelationsanalyse durchführen: {e}\")\n",
    "        results['correlation'] = None\n",
    "    \n",
    "    # 7. Renditeberechnung (spezifisch für Aktiendaten)\n",
    "    print(\"\\n7. RENDITEANALYSE\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    if 'Close' in df.columns:\n",
    "        # Tägliche Renditen\n",
    "        df['Daily_Return'] = df['Close'].pct_change()\n",
    "        \n",
    "        # Logarithmische Renditen\n",
    "        df['Log_Return'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "        \n",
    "        # Statistiken der Renditen\n",
    "        returns_stats = df[['Daily_Return', 'Log_Return']].describe()\n",
    "        print(\"Renditestatistiken:\")\n",
    "        print(returns_stats)\n",
    "        \n",
    "        # Annualisierte Rendite und Volatilität\n",
    "        # Annahme: 252 Handelstage pro Jahr\n",
    "        annual_return = df['Daily_Return'].mean() * 252\n",
    "        annual_volatility = df['Daily_Return'].std() * np.sqrt(252)\n",
    "        \n",
    "        print(f\"\\nAnnualisierte Rendite: {annual_return:.4f} ({annual_return*100:.2f}%)\")\n",
    "        print(f\"Annualisierte Volatilität: {annual_volatility:.4f} ({annual_volatility*100:.2f}%)\")\n",
    "        \n",
    "        # Sharpe Ratio (Annahme: risikofreier Zinssatz von 0%)\n",
    "        sharpe_ratio = annual_return / annual_volatility\n",
    "        print(f\"Sharpe Ratio: {sharpe_ratio:.4f}\")\n",
    "        \n",
    "        results['returns'] = {\n",
    "            'stats': returns_stats.to_dict(),\n",
    "            'annual_return': float(annual_return),\n",
    "            'annual_volatility': float(annual_volatility),\n",
    "            'sharpe_ratio': float(sharpe_ratio)\n",
    "        }\n",
    "    else:\n",
    "        print(\"Keine 'Close'-Spalte für die Renditeberechnung gefunden.\")\n",
    "        results['returns'] = None\n",
    "    \n",
    "    # 8. Zusammenfassung der wichtigsten Erkenntnisse\n",
    "    print(\"\\n8. ZUSAMMENFASSUNG\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    print(f\"- Der Datensatz umfasst {len(df)} Datenpunkte über {(df.index.max() - df.index.min()).days} Tage.\")\n",
    "    print(f\"- Es gibt {total_missing} fehlende Werte ({total_missing_percent:.2f}% der Gesamtdaten).\")\n",
    "    \n",
    "    if 'Close' in df.columns:\n",
    "        print(f\"- Die Aktie hat eine annualisierte Rendite von {annual_return*100:.2f}% bei einer Volatilität von {annual_volatility*100:.2f}%.\")\n",
    "        print(f\"- Die Sharpe Ratio beträgt {sharpe_ratio:.4f}.\")\n",
    "    \n",
    "    # Identifiziere hochkorrelierte Spalten\n",
    "    if results['correlation'] is not None:\n",
    "        high_corr_pairs = []\n",
    "        \n",
    "        for i in range(len(corr.columns)):\n",
    "            for j in range(i+1, len(corr.columns)):\n",
    "                if abs(corr.iloc[i, j]) > 0.8:  # Hohe Korrelation\n",
    "                    high_corr_pairs.append((corr.columns[i], corr.columns[j], corr.iloc[i, j]))\n",
    "        \n",
    "        if high_corr_pairs:\n",
    "            print(\"\\nHoch korrelierte Variablen:\")\n",
    "            for var1, var2, corr_val in high_corr_pairs:\n",
    "                print(f\"- {var1} und {var2}: {corr_val:.4f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausführung der Download Funktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verwendung der Funktion\n",
    "if __name__ == \"__main__\":\n",
    "    # Aktien Daten herunterladen\n",
    "    data = download_stock_data(\"005930.KS\", \"max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausführen der Analyse Funktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Beispiel für die Verwendung\n",
    "if __name__ == \"__main__\":\n",
    "    # Passe den Pfad zur tatsächlichen CSV-Datei an\n",
    "    file_path = \"../data/msft_aktien_daten.csv\"\n",
    "    analysis_results = analyze_stock_data(file_path)\n",
    "    \n",
    "    # Die Ergebnisse sind als Dictionary verfügbar und können weiterverarbeitet werden\n",
    "    if analysis_results:\n",
    "        print(\"\\nAnalyse abgeschlossen!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.10.7"
=======
   "version": "3.9.6"
>>>>>>> feature/Fabian
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
